[["introduction-to-r.html", "R Course Chapter 1 Introduction to R 1.1 What is R? 1.2 Historical Background and Development of R 1.3 R’s Significance in Statistical Computing 1.4 Why Should I Learn R? 1.5 Setting Up R and RStudio 1.6 Using RStudio 1.7 Chapter 1: Assignment", " R Course Basim Alsaedi Chapter 1 Introduction to R 1.1 What is R? R stands as a formidable and highly adaptable programming language specifically designed for statistical computing, data analysis, and data science. Developed by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand, in the early 1990s, R has evolved into an open-source programming language, boasting an extensive suite of statistical and graphical features. 1.1.1 R as a Statistical Computing Environment R serves as a comprehensive statistical computing environment, providing an expansive repertoire of tools and libraries tailored for data manipulation, statistical modeling, and visualization. Its strength lies in its ability to handle and analyze large datasets efficiently, making it a preferred choice for statisticians, data scientists, and researchers across various domains. 1.2 Historical Background and Development of R 1.2.1 Origins of R The roots of R can be traced back to the S language, developed at Bell Laboratories in the 1970s by John Chambers and his colleagues. R emerged as an open-source implementation of the S language, offering a free alternative to proprietary statistical software. 1.2.2 Evolution and Community Involvement Over the years, R has undergone continuous development and improvement, driven by a very vibrant and active community of developers and statisticians. The Comprehensive R Archive Network (CRAN) serves as a central repository for R packages, fostering collaboration and sharing of statistical methodologies and tools. 1.3 R’s Significance in Statistical Computing 1.3.1 Statistical Analysis R is renowned for its extensive statistical functions and packages, making it an ideal tool for data analysis and hypothesis testing. From basic descriptive statistics to advanced modeling techniques, R provides a wide array of tools to analyze and interpret data. 1.3.2 Data Visualization One of R’s standout features is its robust data visualization capabilities. The ggplot2 package, for example, allows users to create a wide range of high-quality graphs and charts, enabling effective communication of data insights. 1.3.3 Machine Learning In machine learning, R has gained popularity with packages like caret, randomForest, and xgboost. These packages facilitate the implementation of various machine learning algorithms, empowering users to build predictive models and conduct advanced analytics. 1.4 Why Should I Learn R? As a specialized language meticulously designed for statistical computing and data analysis, R stands out as a powerful ally for professionals and enthusiasts alike. By mastering R, you gain access to a versatile toolset that empowers you to efficiently handle and analyze vast and diverse datasets, conduct robust statistical analyses, and create captivating visualizations. The open-source nature of R, coupled with its extensive community support and continuous evolution, ensures that you stay at the forefront of advancements in statistical methodologies and cutting-edge tools. Whether you are a statistician, data scientist, researcher, or professional from any domain, learning R opens doors to a realm of possibilities, enabling you to elevate your skills and make meaningful contributions in your chosen field. In this course, you will learn about R’s immense potential in terms of statistical computing and you will be equipped with the skills to know how to harness this potential and apply it in any field you might need to use R in. 1.5 Setting Up R and RStudio RStudio is an Integrated Development Environment (IDE) that gives us a single place to code and manage a project in R. To use RStudio, you need to install R first. You can install the appropriate version of R for your system here: Download R for Windows Download R for MAC After downloading, follow the instructions to install R on your computer. After R is successfully installed, you can install RStudio. - Download RStudio for Windows - Download RStudio for MAC 1.6 Using RStudio After successfully downloading R and RStudio, you are finally ready to start coding in R! Wait… or are you? It is often best practice to learn how to create a project in R. What is a project? A project is like a central where all your R code files can be stored and also any data you might work with. It is important as it makes your program much more organized and will save you a lot of headache when you code. 1.6.1 RStudio Interface To create a new project, navigate to top-left of your window to 1. File -&gt; New Project 2. Select New Directory 3. Select New Project 4. Enter a name for your project 5. Click on Create Project And voila! You have created your first project in R 1.6.2 R Console The R Console is where all the R code you type will be executed. It serves as a command line interpreter which allows you to execute R code one line by a time. 1.6.3 R Script In the context of coding, typing R code one at a time is not effective. Enter R scripts! An R Script is basically a plain text file containing multiple lines or sequences of R code. Scripts are better as they make our code organized, readable and reproducible. QUICK TIP: To create a new R Script, you can use Ctrl + Shift + N 1.6.4 Other Interfaces There is a pane for Environment where all objects created by your code are stored. History where all the previous code you run are kept. There is a pane where you can see your project files, plots created by your code, as well as packages on your system. RStudio provides a user-friendly environment for coding debugging and data visualization. It features a script editor, a console, a workspace viewer, enhanced functionality for package management and even version control! 1.7 Chapter 1: Assignment Reading Materials: https://www.r-project.org/about.html https://en.wikipedia.org/wiki/R_(programming_language) https://data-flair.training/blogs/why-learn-r/ Write a short essay (2 paragraphs maximum) about what you have learned about Install R on your machine using the instructions from this chapter Install RStudio on your machine after installing R. Create your first R Script and do the following: After a # at the beginning of each line, enter your name, your class and group Save the R script as script.R "],["data-types-and-data-structures.html", "Chapter 2 DATA TYPES AND DATA STRUCTURES 2.1 DATA TYPES 2.2 DATA STRUCTURES 2.3 CODE CHALLENGE", " Chapter 2 DATA TYPES AND DATA STRUCTURES 2.1 DATA TYPES In our previous lesson when talking about variables we brushed up on some of the data types in R. There are more data types in R but for the purpose of this course, we will introduce 4 basic data types and they are: - numeric - character - logical - integer 2.1.1 Numeric (num) In R the numeric data type is used to represent both integers and decimals and are stored in double-precision format by default. Examples: 10, 3.14, -7 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIE51bWVyaWMgZGF0YSBleGFtcGxlc1xueCA8LSAxMFxueSA8LSAzLjE0XG56IDwtIC03XG5cbiMgUHJpbnQgbnVtZXJpYyB2YXJpYWJsZXNcbnhcbnlcbnoifQ== Your turn! Assign 57 to a, -35 to b and 100 to c below and print all three like we did above. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEFzc2lnbiBhIG51bWJlciIsInNvbHV0aW9uIjoiYSA8LSA1N1xuYiA8LSAtMzVcbmMgPC0gMTAwXG5cbiMgUHJpbnQgdmFyaWFibGVzXG5hXG5iXG5jIn0= If you did it right, your code should print 57, -35 and 100. 2.1.2 Character (chr) The character data type represents text strings enclosed in single or double quotes. The character data type is used for names, labels and other non-numeric data We will assign the Pamela to a variable called name below. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHN0cmluZyBkYXRhIHR5cGVcbm5hbWUgPC0gXCJQYW1lbGFcIlxuXG4jIFByaW50IG5hbWVcbm5hbWUifQ== In R, you can assign more than one word to a variable. Supposing we wanted to print Pamela’s full name, we can store her full name as a character data type and assign to a new variable called full_name. Pamela’s full name is Pamela Beesly assign that to the variable full_name and print out full name. TIP: Remember, in R, if you want to store a character type, you must enclose it in single or double quotes! eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEFzc2lnbiBQYW1lbGEgQmVlc2x5IHRvIGZ1bGxfbmFtZVxuXG4jIFByaW50IGZ1bGxfbmFtZSIsInNvbHV0aW9uIjoiIyBBc3NpZ24gUGFtZWxhIEJlZXNseSB0byBmdWxsX25hbWVcbmZ1bGxfbmFtZSA8LSBcIlBhbWVsYSBCZWVzbHlcIlxuXG4jIFByaW50IGZ1bGxfbmFtZVxuZnVsbF9uYW1lIn0= 2.1.3 Logical (logi) This data type is used to represent Boolean values: either TRUE or FALSE. Logical data types are used for logical operations and conditional statements which for the sake of understandimg and the workflow of this course, we will discuss later. 2.1.4 Integer (int) Integers, slightly different from the numeric data types are used to represent whole numbers without decimals. To create them, you explicitly need to add the L suffix. Examples are 10L, -5L eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFBvc2l0aXZlIGludGVnZXJcbmludGVnZXJfcG9zaXRpdmUgPC0gODVMXG5cbiMgTmVnYXRpdmUgaW50ZWdlclxuaW50ZWdlcl9uZWdhdGl2ZSA8LSAtMTdMXG5cbiMgWmVybyBhcyBhbiBpbnRlZ2VyXG5pbnRlZ2VyX3plcm8gPC0gMExcblxuIyBMYXJnZSBwb3NpdGl2ZSBpbnRlZ2VyXG5sYXJnZV9pbnRlZ2VyIDwtIDEwMDAwMDBMXG5cbiMgUHJpbnQgaW50ZWdlcnNcbmludGVnZXJfcG9zaXRpdmVcbmludGVnZXJfbmVnYXRpdmVcbmludGVnZXJfemVyb1xubGFyZ2VfaW50ZWdlciJ9 Keep in mind that in many cases, R will automatically coerce numeric values to integers if they don’t have decimal parts, so the L suffix is not always required but can be used for explicit casting. Go ahead and create 3 integers of any number of your choice in the code chunk below and print them. Remember to explicitly use the L suffix. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEFzc2lnbiBpbnRlZ2Vyc1xuXG5cbiMgUHJpbnQgdmFyaWFibGVzIiwic29sdXRpb24iOiIjIFRoaXMgaXMgYSBzYW1wbGUgb2YgaG93IHlvdXIgYW5zd2VyIHNob3VsZCBsb29rIGxpa2UsIHZhbHVlcyBtYXkgZGlmZmVyXG54IDwtIDNMXG55IDwtIDlMXG56IDwtIDI3TFxuXG4jIFByaW50IHZhcmlhbGVzXG54XG55XG56In0= In R, you can use single or double quotes to represent strings and the issue arises when you use them together, for example an apostrophe in a string. We will talk about this in more detail later but for here is how to deal with an apostrophe: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHN0cmluZyB3aXRoIGFuIGFwb3N0cm9waGVcbmNvbXBsYWludCA8LSBcIk15IG5hbWUgaXNuJ3QgaGVyZSFcIlxuXG5jb21wbGFpbnQifQ== Can you create a string with an apostrophe like this: Learning R doesn't stop being fun! Would you wrap this in single or double quotes? Try your answer below. Remember to assign to a variable so you can print it. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEFzc2lnbiBzdHJpbmcgdG8gYW55IHZhcmlhYmxlIG9mIHlvdXIgY2hvaWNlXG5cbiMgUHJpbnQgdGhlIHZhcmlhYmxlIiwic29sdXRpb24iOiIjIEFzc2lnbiBzdHJpbmdcbnR4dCA8LSBcIkxlYXJuaW5nIFIgZG9lc24ndCBzdG9wIGJlaW5nIGZ1biFcIlxuXG4jIFByaW50IHZhcmlhYmxlXG50eHQifQ== 2.2 DATA STRUCTURES Data structures in R are used to organize and store data to facilitate efficient access and further manipulation. There are a number of data structures in R but we will talk about the most important ones: - Vectors - Matrices - Lists - Dataframes - Factors 2.2.1 Vector Vectors are the most fundamental data structure in R. You will find as you journey further down your R path that, they are the building blocks for almost all other data structures. Vectors are one-dimensional, storing elements in a single sequence and they are homogeneous. Vectors’ homogeneity means that all elements in a vector must be of the same data type and are dynamic. You can grow or shrink a vector. 2.2.1.1 Creating a vector You can create a vector in R using the c() function, which stands for “combine” or “concatenate.” eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG51bWVyaWMgdmVjdG9yXG5udW1iZXJzIDwtIGMoMSwgMiwgMywgNCwgNSlcblxuIyBQcmludCB2ZWN0b3Jcbm51bWJlcnMifQ== There is also a trick to create a sequence of vectors. We simply use the : operator like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHNlcXVlbmNlIG9mIHZlY3RvcnNcbnllYXJzIDwtIDIwMDA6MjAxMFxuXG4jIFByaW50IHllYXJzXG55ZWFycyJ9 Create your own sequence of vectors called that is a sequence of even numbers from 15 to 28 below. Choose a descriptive variable name and print it when you assign it! eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHZlY3RvciBjb250YWluaW5nIGEgc2VxdWVuY2Ugb2YgbnVtYmVycyBmcm9tIDE1IHRvIDI4XG5cbiMgUHJpbnQgdmVjdG9yIiwic29sdXRpb24iOiIjIENyZWF0ZSB2ZWN0b3JcbnZlYyA8LSAxNToyOFxuXG4jIFByaW50XG52ZWMifQ== We can also create character vectors that contain strings of text! eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFZlY3RvciBvZiBuYW1lc1xubmFtZXMgPC0gYyhcIkZhdGltYVwiLCBcIkJvYlwiLCBcIkhlbGdhXCIpXG5cbiMgUHJpbnQgdmVjdG9yXG5uYW1lcyJ9 2.2.1.2 Accessing an element in a vector To access an element in a vector, we use square brackets and the elements index. Unlike in other programming languages, in R, the index starts at 1. We will first print the names vector to preview how it looks like. We can extract Fatima’s name for example like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFZlY3RvciBvZiBuYW1lc1xubmFtZXMgPC0gYyhcIkZhdGltYVwiLCBcIkJvYlwiLCBcIkhlbGdhXCIpXG5cbm5hbWVzXG5cbiMgRXh0cmFjdCBGYXRpbWFcbm5hbWVzWzFdXG5cbiMgRXh0cmFjdCBIZWxnYVxubmFtZXNbM10ifQ== If you want to extract a vector element. All you need to do is input the vector name followed immediately by square brackets and then input the index of the element you want to extract. if you want to save an extracted element to a variable too, that is possible. Supposing Fatima was the manager, we can save her name to a variable called manager like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFZlY3RvciBvZiBuYW1lc1xubmFtZXMgPC0gYyhcIkZhdGltYVwiLCBcIkJvYlwiLCBcIkhlbGdhXCIpXG5cbiMgU2F2aW5nIGFuIGV4dHJhY3RlZCB2ZWN0b3IgZWxlbWVudCB0byBhIHZhcmlhYmxlXG5tYW5hZ2VyIDwtIG5hbWVzWzFdXG5cbiMgUHJpbnQgbWFuYWdlclxubWFuYWdlciJ9 Create a vector named capitals, containing the capitals of Portugal, Ghana, Canada and Brazil and using the knowledge you’ve just gained, extract the third element in the vector you just created. Assign the extracted element to capital_canada. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHZlY3RvciBvZiBjYXBpdGFscyBhbmQgYXNzaWduIHRvIGNhcGl0YWxzXG5cbiMgUHJpbnQgY2FwaXRhbHMgdmVjdG9yIiwic29sdXRpb24iOiIjIFZlY3RvciBvZiBjYXBpdGFsc1xuY2FwaXRhbHMgPC0gYyhcIkxpc2JvblwiLCBcIkFjY3JhXCIsIFwiT3R0YXdhXCIsIFwiUmlvXCIsIFwiQnJhc2lsaWFcIilcblxuIyBQcmludCBjYXBpdGFsc1xuY2FwaXRhbHMifQ== 2.2.1.3 Basic vector operations Some basic operations we can perform on vectors include arithmetic, logical and indexing which we already talked about. The indexing we will talk about in this subsection would be a little more advanced. Arithmetic operations perform calculations on vectors element-wise, meaning whatever calculation performed on the vector as a whole, would apply to each element the vector contains. Let us define a variable called ages, which will store a vector containing a theoretical age for 10 people. As discussed, arithmetic operations include addition, subtraction, division, multiplication and modulo. Supposing we wanted to double each single age, we can do it like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhZ2VzIHZlY3RvclxuYWdlcyA8LSBjKDEyLCAzNSwgOCwgMTQsIDE5LCAyMiwgNDAsIDI3LCAxMywgMjkpXG5cbiMgRG91YmxlIGFnZXMgdmVjdG9yXG5kb3VibGVkX2FnZXMgPC0gYWdlcyAqIDJcblxuIyBQcmludCByZXN1bHRcbmRvdWJsZWRfYWdlcyJ9 If we want to divide each age, that is possible too. We will call our initial ages vector and divide it by 2 and store the result to a new variable like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEFnZXMgdmVjdG9yXG5hZ2VzIDwtIGMoMTIsIDM1LCA4LCAxNCwgMTksIDIyLCA0MCwgMjcsIDEzLCAyOSlcblxuIyBEaXZpZGUgZWFjaCBhZ2UgaW50byB0d29cbmhhbHZlZF9hZ2VzIDwtIGFnZXMgLyAyXG5cbiMgUHJpbnQgcmVzdWx0XG5oYWx2ZWRfYWdlcyJ9 We can compare elements in a vector and return a logical vector of TRUE’s and FALSE’s if the condition supplied is satisfied or was not satisfied. For example, we can check to see how many elements in our ages vector were even numbers. We can do it using this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFByaW50IGFnZXMgdmVjdG9yXG5hZ2VzIDwtIGMoMTIsIDM1LCA4LCAxNCwgMTksIDIyLCA0MCwgMjcsIDEzLCAyOSlcblxuYWdlc1xuXG4jIENvbmRpdGlvbiB0byBjb21wYXJlIGZvciBldmVuIGFnZXNcbmlzX2V2ZW4gPC0gYWdlcyAlJSAyID09IDBcblxuaXNfZXZlbiJ9 Woahhh! That’s a lot going on. We did not really talk about the modulo operator. In R to check for modulo, you use this %%. There was also a double equal to sign ==, but what was it for. You remember when we talked about variable assignment, we said = is used for variable assignment? In R, to check for equality, you use == instead of the single equal to sign =. In the is_even variable, we tried to store the result of all ages that when divided by 2, leaves no remainder, i.e, remainder will be zero. Printing the vector, we saw a whole lot of TRUE’s and FALSE’s. That is what we call a logical vector. The power of a logical vector comes to life when we combine it with indexing. Do you remember how to index a vector to return an element? We use the double square brackets to do that. Since we have a logical vector that derived it elements from comparing the ages vector to return TRUE or FALSE based on if a condition was met, we can use that vector to return only even ages in our ages vector like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhZ2VzIHZlY3RvclxuYWdlcyA8LSBjKDEyLCAzNSwgOCwgMTQsIDE5LCAyMiwgNDAsIDI3LCAxMywgMjkpXG5cbiMgQ29uZGl0aW9uIHRvIGNvbXBhcmUgZm9yIGV2ZW4gYWdlc1xuaXNfZXZlbiA8LSBhZ2VzICUlIDIgPT0gMFxuXG4jIEZpbHRlciBhZ2VzIHRvIHJldHVybiBldmVuIGFnZXNcbmV2ZW5fYWdlcyA8LSBhZ2VzW2lzX2V2ZW5dXG5cbmV2ZW5fYWdlcyJ9 The dynamism of vectors is such that we can do this directly without creating a logical vector as R will do that in the background. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIGFnZXMgdmVjdG9yXG5hZ2VzIDwtIGMoMTIsIDM1LCA4LCAxNCwgMTksIDIyLCA0MCwgMjcsIDEzLCAyOSlcblxuIyBJbmRleGluZyBkaXJlY3RseSB3aXRob3V0IGV4cGxpY2l0bHkgY3JlYXRpbmcgYSBsb2dpY2FsIHZlY3RvclxuYWdlc1thZ2VzICUlIDIgPT0gMF0ifQ== You will now try in the interactive code chunk below how to subset a vector with a logical vector. Generate a sequence of numbers from 1 to 50 and assign it to ages and then a create a new variable, is_odd, which stores a condition for comparing ages that are odd. You remember a number divided by 2 without a remainder is an even number. A hint for finding an odd number: any number that when divided by 2, leaves a remainder of 1 is an odd number. After you have created is_odd, use it to index the ages vector to return all ages that are odd. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhZ2VzIHZlY3RvclxuXG5cbiMgQ3JlYXRlIGlzX29kZCB2YXJpYWJsZVxuXG5cbiMgSW5kZXggYWdlcyB2ZWN0b3Igd2l0aCBpc19vZGRcblxuXG4jIFByaW50IGFnZXMgdGhhdCBhcmUgb2RkIiwic29sdXRpb24iOiIjIENyZWF0ZSBhZ2VzIHZlY3RvclxuYWdlcyA8LSAxOjUwXG5cbiMgQ3JlYXRlIGlzX29kZFxuaXNfb2RkIDwtIGFnZXMgJSUgMiA9PSAxXG5cbiMgSW5kZXggYWdlcyB2ZWN0b3Igd2l0aCBpc19vZGRcbm9kZF9hZ2VzIDwtIGFnZXNbaXNfb2RkXVxuXG4jIFByaW50IGFnZXMgdGhhdCBhcmUgb2RkXG5vZGRfYWdlcyJ9 Now, recreate ages and index it directly without explicitly creating a logical vector below: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhZ2VzIHZlY3RvclxuXG4jIEluZGV4IGRpcmVjdGx5Iiwic29sdXRpb24iOiIjIENyZWF0ZSBhZ2VzIHZlY3RvclxuYWdlcyA8LSAxOjUwXG5cbiMgU3Vic2V0IGFnZXMgZGlyZWN0bHkgZm9yIG9kZCBhZ2VzXG5hZ2VzW2FnZXMgJSUgMiA9PSAxXSJ9 We will talk about a very important concept called subsetting after we talk about dataframes. 2.2.2 Matrix OK, fine, those bullets were not a very accurate representation of a matrix’s structure but boy was it close! Matrices are two-dimensional data structures in R that arrange elements in rows and columns. They resemble a rectangular grid. Matrices are defined by a specified number of rows and columns and just like vectors, they must contain elements of the same data types and again, just like vectors, elements can be accessed using indices but for matrices, the indexing operation works a bit differently. In vectors where we supplied the index of the element, in a matrix, to access an element, you have to index by using the element’s row and and column indices. More about that shortly but let us talk about creating a matrix. In R we can create a matrix in a number of ways but we will discuss 3 of such ways here. We can create a matrix by using the matrix() function, cbind() or rbind() Using the matrix() function eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG1hdHJpeCBmcm9tIDEgdG8gOVxubmVvX21hdHJpeCA8LSBtYXRyaXgoMTo5LCBucm93ID0gMywgbmNvbCA9IDMpXG5cbiMgUHJpbnQgbWF0cml4XG5uZW9fbWF0cml4In0= You remember in creating vectors, we used : to generate a sequence of numbers from the initial number to the last number supplied? Here we created a matrix by generating a sequence of numbers from 1 to 9 as the data and then we specified the number of rows, 3 rows and number of columns, 3. the resulting matrix was populated by the sequence of numbers column by column. This is the default behavior of R. If we wanted the numbers to be filled row by row, we can add an extra argument like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG1hdHJpeCBmaWxsZWQgYnkgcm93XG5uZW9fbWF0cml4IDwtIG1hdHJpeCgxOjksIG5yb3cgPSAzLCBuY29sID0gMywgYnlyb3cgPSBUUlVFKVxuXG4jIFByaW50IG1hdHJpeFxubmVvX21hdHJpeCJ9 Voilà! We have it. You might just have a little voice in the back of your head wondering why the row and column arguments were 3. When creating a matrix, it is important to ensure the matrix data supplied fit in the matrix structure perfectly. We had 9 elements so we could use the 3x3 format. If we had for example, a matrix of 6 elements, we could have also used a 3 x 2 matrix or a 2 x 3 matrix like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIDMgeCAyXG5tYXRyaXgoMTo2LCBucm93ID0gMywgbmNvbCA9IDIsIGJ5cm93ID0gVFJVRSlcblxuIyAyIHggM1xubWF0cml4KDE6NiwgbnJvdyA9IDIsIG5jb2wgPSAzLCBieXJvdyA9IFRSVUUpIn0= To create a matrix, we can also use the cbind() function. Remember how we said vectors are the building blocks of almost any data structure in R? We can use vectors to create a matrix! eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG1hdHJpeCB1c2luZyB2ZWN0b3JzXG5jb2wxIDwtIGMoMSwgNCwgNylcbmNvbDIgPC0gYygyLCA1LCA4KVxuY29sMyA8LSBjKDMsIDYsIDkpXG5cbiMgVXNlIGNiaW5kIHRvIGNyZWF0ZSB0aGUgbWF0cml4XG5teV9tYXRyaXggPC0gY2JpbmQoY29sMSwgY29sMiwgY29sMylcbm90aGVyX21hdHJpeCA8LSByYmluZChjb2wxLCBjb2wyLCBjb2wzKVxuXG4jIFByaW50IHRoZSBtYXRyaXhcbm15X21hdHJpeFxub3RoZXJfbWF0cml4In0= We used cbind and rbind and we saw two different outputs. But why? cbind in R stands for column bind. It combined the vectors by adding each single vector as a standalone column in the matrix while rbind combines each vector as a row. 2.2.2.1 Indexing a matrix The same way we can access an element in a vector, we can do same with matrices. With a matrix though, you need to supply the elements row index and its column index. The syntax for extracting is simple. matrix[row_index, column_index] You can access an index like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBuZW8gbWF0cml4XG5uZW9fbWF0cml4IDwtIG1hdHJpeCgxOjksIG5yb3cgPSAzLCBuY29sID0gMywgYnlyb3cgPSBUUlVFKVxuXG4jIEFjY2VzcyB0aGUgbnVtYmVyIDZcbm5lb19tYXRyaXhbMiwzXSJ9 Easy! We just extracted the number 6 by supplying the row index and the column index of 6! Can you create a 2 x 6 matrix and populate it row-wise with values from 1:12. Can you index the value 9? Remember to extract a matrix value, you can use square bracket notation and supply the row and column the value is located in. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSAyIHggNiBtYXRyaXhcblxuXG4jIFByaW50IHJlc3VsdCIsInNvbHV0aW9uIjoiIyBDcmVhdGUgMiB4IDYgbWF0cml4XG5tYXQgPC0gbWF0cml4KDE6MTIsIG5yb3cgPSAyLCBuY29sID0gNiwgYnlyb3cgPSBUUlVFKVxuXG4jIEV4dHJhY3QgOVxubWF0WzIsIDNdIn0= In matrices, you can also retrieve all elements in a row or column of a matrix by supplying the row or column index. Remember to access only one value, you have to supply both the row and column index? You can also return an entire matrix row or column by specifying only the row or column you want to extract. To extract a row in a matrix the syntax is: matrix[row_index, ]. You supply the row index and leave the column index empty. You can do that like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIDUgeCA1IG1hdHJpeFxubXlfbWF0cml4IDwtIG1hdHJpeCgxOjI1LCBucm93ID0gNSwgbmNvbCA9IDUpXG5cbiMgUmV0dXJuIHRoZSAzcmQgcm93IG9mIHRoZSBtYXRyaXhcbm15X21hdHJpeFszLCBdIn0= Perfect. Only elements from the third row were returned! How about extracting a column? The syntax is also relatively straightforward. You supply the column index and it will return the all values in that column for you. You use matrix[ , column_index] to extract the column of a matrix. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIG91ciA1eDUgbWF0cml4LCB3ZSBjYW4gZXh0cmFjdCB0aGUgNHRoIGNvbHVtbiBmb3IgZXhhbXBsZSBsaWtlIHRoaXNcbm15X21hdHJpeCA8LSBtYXRyaXgoMToyNSwgbnJvdyA9IDUsIG5jb2wgPSA1KVxuXG5teV9tYXRyaXhbICwgNF0ifQ== This worked too! Now create and extract the 2nd row and then the 5th column of a 7x7 matrix. Remember to know what range of values to use, multiply the number of rows and columns and use that for your data argument when creating your matrix eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB5b3VyIDd4NyBtYXRyaXggYW5kIGFzc2lnbiBpdCB0byBhIHZhcmlhYmxlXG5cblxuIyBFeHRyYWN0IHRoZSAybmQgcm93XG5cblxuIyBFeHRyYWN0IHRoZSA1dGggY29sdW1uIiwic29sdXRpb24iOiIjIENyZWF0ZSB5b3VyIDd4NyBtYXRyaXggYW5kIGFzc2lnbiBpdCB0byBhIHZhcmlhYmxlXG5tYXQgPC0gbWF0cml4KDE6NDksbnJvdyA9IDcsIG5jb2wgPSA3KVxuXG4jIEV4dHJhY3QgdGhlIDJuZCByb3dcbm1hdFsyLCBdXG5cbiMgRXh0cmFjdCB0aGUgNXRoIGNvbHVtblxubWF0WyAsIDVdIn0= The basic matrix operations we will discuss here are arithmetic operations and transposing. 2.2.2.2 Matrix Addition For arithmetic operations, we can add, subtract multiply and divide. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJtYXRyaXgxIDwtIG1hdHJpeCgxOjQsIG5yb3cgPSAyKVxubWF0cml4MiA8LSBtYXRyaXgoNTo4LCBucm93ID0gMilcblxubWF0cml4MVxubWF0cml4MlxuXG5yZXN1bHQgPC0gbWF0cml4MSArIG1hdHJpeDIgICMgRWxlbWVudC13aXNlIGFkZGl0aW9uXG5yZXN1bHQifQ== You can also add multiple matrices too! eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERlZmluZSBtYXRyaWNlc1xubWF0cml4X2EgPC0gbWF0cml4KDE6NCwgbnJvdyA9IDIsIGJ5cm93ID0gVFJVRSlcbm1hdHJpeF9iIDwtIG1hdHJpeCg1OjgsIG5yb3cgPSAyLCBieXJvdyA9IFRSVUUpXG5tYXRyaXhfYyA8LSBtYXRyaXgoOToxMiwgbnJvdyA9IDIsIGJ5cm93ID0gVFJVRSlcblxuIyBBZGQgbWF0cmljZXNcbnJlc3VsdCA8LSBtYXRyaXhfYSArIG1hdHJpeF9iICsgbWF0cml4X2NcbnJlc3VsdCJ9 Define and add two 3x3 matrices in the code chunk below. You can use absolutely any values you want for your matrices. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gM3gzIG1hdHJpY2VzXG5cbiMgQWRkIHggYW5kIHkiLCJzb2x1dGlvbiI6IiMgQ3JlYXRlIHR3byAzeDMgbWF0cmljZXNcbnggPC0gbWF0cml4KDk6MTcsIG5yb3cgPSAzLCBuY29sPTMpXG55IDwtIG1hdHJpeCgyNzozNSwgbnJvdyA9IDMsIG5jb2wgPSAzKVxuXG4jIEFkZCB4IGFuZCB5XG5yZXN1bHQgPC0geCArIHlcbnJlc3VsdCJ9 You can also subtract matrices. It follows the same process as addition. Can you create and subtract 2 matrices below? Ensure the matrices are the same size! 2.2.2.3 Matrix subtraction eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gbWF0cmljZXNcblxuXG4jIFBlcmZvcm0gb3BlcmF0aW9uIGFuZCBwcmludCByZXN1bHQiLCJzb2x1dGlvbiI6IiMgQ3JlYXRlIHR3byAzeDMgbWF0cmljZXNcbnggPC0gbWF0cml4KDE3OjI1LCBucm93ID0gMywgbmNvbD0zKVxueSA8LSBtYXRyaXgoMjoxMCwgbnJvdyA9IDMsIG5jb2wgPSAzKVxuXG4jIEFkZCB4IGFuZCB5XG5yZXN1bHQgPC0geCAtIHlcbnJlc3VsdCJ9 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERlZmluZSB0d28gbWF0cmljZXMgd2l0aCBkaWZmZXJlbnQgZGltZW5zaW9uc1xubWF0cml4X2EgPC0gbWF0cml4KDE6NCwgbnJvdyA9IDIsIGJ5cm93ID0gVFJVRSlcbm1hdHJpeF9iIDwtIG1hdHJpeCg1OjgsIG5yb3cgPSAyLCBieXJvdyA9IFRSVUUpXG5cbiMgQXR0ZW1wdCB0byBhZGQgbWF0cmljZXMgd2l0aCBkaWZmZXJlbnQgZGltZW5zaW9uc1xucmVzdWx0IDwtIG1hdHJpeF9hICsgbWF0cml4X2JcbnJlc3VsdCJ9 2.2.2.4 Matrix Multiplication When multiplying matrices, the process is distinct from regular element-wise multiplication. Each element in the result is determined by taking the sum of the products obtained by multiplying corresponding elements of a row in the first matrix with the elements in the corresponding column of the second matrix. This systematic pairing of row and column elements across the matrices ensures that the resulting matrix reflects the combined influence of the interactions between each element in the two matrices. Matrix multiplication is subject to specific requirements to ensure a valid operation. The key conditions include having compatible inner dimensions, where the number of columns in the first matrix must match the number of rows in the second matrix. The resultant matrix will then have dimensions corresponding to the outer dimensions of the matrices being multiplied. The operation is associative, allowing flexibility in the order of multiplication. These prerequisites ensure that the systematic pairing of row and column elements, as described in the multiplication process, aligns appropriately, and the resulting matrix accurately captures the combined interactions between elements from the two matrices. # add matrix multiplication images There is a slight syntax difference you would have to pay attention to when it comes to matrix multiplication. The multiplication operator for matrices is not the regular *. For matrix multiplication, the %\\*% operator is used. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERlZmluZSB0d28gbWF0cmljZXNcbm1hdHJpeDEgPC0gbWF0cml4KDE6NCwgbnJvdyA9IDIpXG5tYXRyaXgxXG5cbm1hdHJpeDIgPC0gbWF0cml4KDU6OCwgbnJvdyA9IDIpXG5tYXRyaXgyXG5cbiMgTXVsdGlwbHkgbWF0cmljZXMgQSBhbmQgQlxucmVzdWx0IDwtIG1hdHJpeDEgJSolIG1hdHJpeDJcbnJlc3VsdCJ9 Woah woah woah… What is going on? You have forgotten all about your matrix lessons back in math class. Each element in the result is computed by taking the sum of the products obtained by multiplying corresponding elements of a row in the first matrix with the elements in the corresponding column of the second matrix. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERlZmluZSB0d28gbWF0cmljZXNcbm1hdHJpeDEgPC0gbWF0cml4KDE6NCwgbnJvdyA9IDIpXG5tYXRyaXgyIDwtIG1hdHJpeCg1OjgsIG5yb3cgPSAyKVxuXG4jIFByaW50IG91dCBib3RoIG1hdHJpY2VzXG5tYXRyaXgxXG5tYXRyaXgyIn0= From the above result, we can see the elements of our matrices. Matrix multiplication follows exactly the same concept you learned in math class. The first row in the first matrix is multiplied by the first column in the second matrix and the products are added to get the first value of the resulting matrix. For matrix 1 and 2 above, this is what happens behind the scenes: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjcmVzdWx0ID0gfCAoMSo1ICsgMyo2KSAgKDEqNyArIDMqOCkgfFxuIyAgICAgICAgIHwgKDIqNSArIDQqNikgICgyKjcgKyA0KjgpIHwifQ== eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERlZmluZSB0d28gbWF0cmljZXNcbm1hdHJpeF9hIDwtIG1hdHJpeCgxOjQsIG5yb3cgPSAyKVxubWF0cml4X2IgPC0gbWF0cml4KGMoNSwgNiksIG5yb3cgPSAyLCBuY29sID0gMSlcblxubWF0cml4X2Fcbm1hdHJpeF9iXG5cbiMgTXVsdGlwbHkgYm90aCBcbnJlc3VsdCA8LSBtYXRyaXhfYSAlKiUgbWF0cml4X2JcbnJlc3VsdCJ9 This multiplication did not have two matrices of similar dimension yet it worked. Why? In matrix multiplication, the number of columns in the first matrix must always match the number of rows in the second matrix for the multiplication to be successful. matrix_a had two columns and matrix_b had two rows so our matrix multiplication is valid. Create two 2x3 matrices below, matrix3 and matrix4. The values of matrix3 is a sequence of numbers from 1 to 6 and the value of matrix4 is from 7 to 12. Multiply these two matrices and return a result. Do you understand the output and how it was obtained? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gMngzIG1hdHJpY2VzXG5cblxuIyBNdWx0aXBseSBib3RoIG1hdHJpY2VzIiwic29sdXRpb24iOiIjIENyZWF0ZSB0d28gMngzIG1hdHJpY2VzXG5tYXRyaXgzIDwtIG1hdHJpeCgxOjYsIG5yb3cgPSAyLCBuY29sID0gMylcbm1hdHJpeDQgPC0gbWF0cml4KDc6MTIsIG5yb3cgPSAyLCBuY29sID0gMylcblxuIyBNdWx0aXBseSBib3RoIG1hdHJpY2VzXG5yZXN1bHQgPC0gbWF0cml4MyAqIG1hdHJpeDRcbnJlc3VsdCJ9 We can also transpose a matrix, swapping the rows and columns of a matrix by using the t() function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBtYXRyaXhcbm1hdHJpeCA8LSBtYXRyaXgoMTo2LCBucm93ID0gMilcblxuIyBQcmludCBpbml0aWFsIG1hdHJpeFxubWF0cml4XG5cbiMgUGVyZm9ybSB0cmFuc3Bvc2Ugb3BlcmF0aW9uXG50cmFuc3Bvc2VkIDwtIHQobWF0cml4KVxuXG4jIFByaW50IHRyYW5zcG9zZWQgbWF0cml4XG50cmFuc3Bvc2VkIn0= As we can see, the rows in the initial matrix have been swapped by the columns in the second matrix. 2.2.3 Lists A list in R is a flexible data structure that can hold elements of of different data types. This flexibility makes lists the perfect data structure for organizing complex data and creating hierarchical structures. Lists in R, just like vectors, are ordered. Each element in a list have a specific order and can be accessed by an index. Lists, unlike vectors and matrices, can be heterogeneous, meaning they can contain elements of varying data types including numbers, characters, matrices, vectors and even other lists! A very key fact to note about lists is that, they are mutable. When a list is created, elements can be added, removed and/or even modified after creation. All this flexibility makes lists very versatile for various tasks. In R, to create a list, you simply use the list() function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGJhc2ljIGxpc3Rcbm15X2xpc3QgPC0gbGlzdCgxOjUsIFwiaG9sYVwiLCBUUlVFLCBsaXN0KGMoMTAsMjApKSlcblxuIyBQcmludCBvdXQgY3JlYXRlZCBsaXN0XG5teV9saXN0In0= Oh nice spot! you saw how we created our embedded list with a vector. Yes, just as we initially discussed, vectors do form the building blocks of a lot of data structures in R! For our my_list list, we first generated a sequence of numbers from 1 to 5, added the character \"hola\", the Boolean TRUE and another list containing 10 and 20. when we printed out our list we saw our code run successfully without throwing up any error despite the rather odd assembly of elements in the list. This is the dirty beauty of lists. They can store any type of data without complaining. With vectors and matrices, we used a square bracket to access the elements they contained that we wanted to extract. When it comes to list however, accessing individual elements has a slight syntax difference. Instead of using a single square bracket, we use a double square bracket like this list[[index/name]] Let us see this in action. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFByaW50IG91dCBwcmV2aW91c2x5IGNyZWF0ZWQgbGlzdFxubXlfbGlzdCA8LSBsaXN0KDE6NSwgXCJob2xhXCIsIFRSVUUsIGxpc3QoYygxMCwyMCkpKVxuXG5teV9saXN0In0= Now let us extract the greeting “hola” by using its index. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExpc3Rcbm15X2xpc3QgPC0gbGlzdCgxOjUsIFwiaG9sYVwiLCBUUlVFLCBsaXN0KGMoMTAsMjApKSlcblxuIyBFeHRyYWN0IGdyZWV0aW5nXG5ncmVldGluZyA8LSBteV9saXN0W1syXV1cblxuIyBQcmludCBncmVldGluZ1xuZ3JlZXRpbmcifQ== You remember in the syntax, we discussed that a list element can be accessed by using its index or name? In our initially created list, we did not name our list elements so let us go on and see how a named list looks like eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG5hbWVkIGxpc3RcbmNoYW1waW9ucyA8LSBsaXN0KHRlYW0gPSBcIlJlYWwgTWFkcmlkXCIsXG4gICAgICAgICAgICAgICAgICBjb3VudHJ5ID0gXCJTcGFpblwiLFxuICAgICAgICAgICAgICAgICAgc2Vhc29uID0gMjAxOCxcbiAgICAgICAgICAgICAgICAgIGNpdHkgPSBcIktpZXZcIixcbiAgICAgICAgICAgICAgICAgIHRvdGFsID0gMTMpIn0= We have created a named list containing the winners of the 2017-2018 UEFA Champions League. To extract Real Madrid, the name of the team that won the competition, we can do it like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG5hbWVkIGxpc3RcbmNoYW1waW9ucyA8LSBsaXN0KHRlYW0gPSBcIlJlYWwgTWFkcmlkXCIsXG4gICAgICAgICAgICAgICAgICBjb3VudHJ5ID0gXCJTcGFpblwiLFxuICAgICAgICAgICAgICAgICAgc2Vhc29uID0gMjAxOCxcbiAgICAgICAgICAgICAgICAgIGNpdHkgPSBcIktpZXZcIixcbiAgICAgICAgICAgICAgICAgIHRvdGFsID0gMTMpXG5cbiMgRXh0cmFjdCBuYW1lIG9mIHRlYW1cbndpbm5lciA8LSBjaGFtcGlvbnNbW1widGVhbVwiXV1cblxuIyBQcmludCBvdXQgcmVzdWx0XG53aW5uZXIifQ== Do note that, when extracting elements from a named list, you have to put the name in quotes so R understands you are extracting a value from the named list. Doing otherwise will throw up an error as R will think it is a variable. We can have more examples by trying to extract other parts of the champions list below. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG5hbWVkIGxpc3RcbmNoYW1waW9ucyA8LSBsaXN0KHRlYW0gPSBcIlJlYWwgTWFkcmlkXCIsXG4gICAgICAgICAgICAgICAgICBjb3VudHJ5ID0gXCJTcGFpblwiLFxuICAgICAgICAgICAgICAgICAgc2Vhc29uID0gMjAxOCxcbiAgICAgICAgICAgICAgICAgIGNpdHkgPSBcIktpZXZcIixcbiAgICAgICAgICAgICAgICAgIHRvdGFsID0gMTMpXG5cbiMgRXh0cmFjdCBzZWFzb24gZnJvbSBjaGFtcGlvbnNcbmNoYW1waW9uc1tbXCJzZWFzb25cIl1dXG5cbiMgRXh0cmFjdCB0b3RhbCB0aXRsZXMgZnJvbSBjaGFtcGlvbnNcbmNoYW1waW9uc1tbXCJ0b3RhbFwiXV0ifQ== With lists, the basic operations apart from element extraction would be basic list manipulation operations such as adding and removing elements in them as well as combining lists. To add new list elements, you can add the new index and assign the new element you want to add to that list. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGJhc2ljIGxpc3RcbmRldGFpbHMgPC0gbGlzdChcIkpvaG5cIiwgNDMsIFwiTmV3IFlvcmtcIilcblxuIyBBZGQgYSBuZXcgZWxlbWVudCB0byB0aGUgbGlzdDogcG9zdGNvZGVcbmRldGFpbHNbWzRdXSA8LSAxMDAwMVxuXG4jIFByaW50IGRldGFpbHMgYWdhaW5cbmRldGFpbHMifQ== The syntax for this is very simple. To remove an element, we specify the element’s index and then remove it by specifying the index and assigning NULL to that index. Supposing John is a little ashamed of his age and wants that removed, we can do that like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGJhc2ljIGxpc3RcbmRldGFpbHMgPC0gbGlzdChcIkpvaG5cIiwgNDMsIFwiTmV3IFlvcmtcIilcblxuIyBSZW1vdmUgYWdlXG5kZXRhaWxzW1syXV0gPC0gTlVMTFxuXG4jIFJlcHJpbnQgZGV0YWlsc1xuZGV0YWlscyJ9 We can also combine other lists into a single one like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gYmFzaWMgbGlzdHNcbmxpc3QxIDwtIGxpc3QoYSA9IDEsIGIgPSAyLCBjID0gMylcbmxpc3QyIDwtIGxpc3QoZCA9IDQsIGUgPSA1LCBmID0gNilcblxuIyBDb21iaW5lIHRoZSBsaXN0c1xuY29tYmluZWRfbGlzdCA8LSBjKGxpc3QxLCBsaXN0MilcblxuIyBQcmludCB0aGUgY29tYmluZWQgbGlzdFxuY29tYmluZWRfbGlzdCJ9 Note that this is recommended only for lists which do not contain duplicates. If you have lists that contain duplicates you should consider using the append() function, as that joins both lists without overwriting duplicate elements. Take a look at this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gbGlzdHMgd2l0aCBkdXBsaWNhdGVzXG5saXN0MSA8LSBsaXN0KGEgPSAxLCBiID0gMiwgYSA9IDMpXG5saXN0MiA8LSBsaXN0KGIgPSA0LCBjID0gNSwgYyA9IDYpXG5cbiMgQ29tYmluZSBsaXN0cyB3aXRob3V0IG92ZXJ3cml0aW5nIGR1cGxpY2F0ZXNcbmNvbWJpbmVkX2xpc3QgPC0gYXBwZW5kKGxpc3QxLCBsaXN0MilcblxuIyBQcmludCB0aGUgY29tYmluZWQgbGlzdFxucHJpbnQoY29tYmluZWRfbGlzdCkifQ== Another example of combining lists but with different elements like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gbGlzdHMgd2l0aCBkaWZmZXJlbnQgdHlwZXMgb2YgZWxlbWVudHNcbmVtcGxveWVlX2luZm8gPC0gbGlzdChuYW1lID0gXCJNaWNoYWVsIFNjb3R0XCIsIGFnZSA9IDM3LCBkZXBhcnRtZW50ID0gXCJIUlwiKVxuY29udGFjdF9pbmZvIDwtIGxpc3QoZW1haWwgPSBcIm1pY2hhZWwuc2NvdHRAZHVuZGVybWlmZmxpbi5jb21cIixcbiAgICAgICAgICAgICAgICAgICAgIHBob25lID0gXCIxMjMtNDU2LTc4OTBcIixcbiAgICAgICAgICAgICAgICAgICAgIGFkZHJlc3MgPSBcIjEyMyBTY3JhbnRvbiBTdFwiKVxuXG4jIENvbWJpbmUgdGhlIGxpc3RzXG5jb21iaW5lZF9pbmZvIDwtIGMoZW1wbG95ZWVfaW5mbywgY29udGFjdF9pbmZvKVxuXG4jIFByaW50IHRoZSBjb21iaW5lZCBsaXN0XG5jb21iaW5lZF9pbmZvIn0= Create two separate lists: personal_info and academic_info. The first list includes personal details such as the name (“Alice”), age (20), and gender (“Female”). The second list, academic_info, contains academic information like the major (“Computer Science”), GPA (3.8), and year (“Junior”). Combine these two lists into one below: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSB0d28gbGlzdHM6IHBlcnNvbmFsX2luZm8gYW5kIGFjYWRlbWljX2luZm9cblxuIyBDb21iaW5lIGxpc3QiLCJzb2x1dGlvbiI6IiMgV3JpdGUgeW91ciBjb2RlIGJlbG93IHRoaXMgbGluZVxucGVyc29uYWxfaW5mbyA8LSBsaXN0KG5hbWUgPSBcIkFsaWNlXCIsXG4gICAgICAgICAgICAgICAgICAgICAgYWdlID0gMjAsXG4gICAgICAgICAgICAgICAgICAgICAgZ2VuZGVyID0gXCJGZW1hbGVcIilcblxuYWNhZGVtaWNfaW5mbyA8LSBsaXN0KG1ham9yID0gXCJDb21wdXRlciBTY2llbmNlXCIsXG4gICAgICAgICAgICAgICAgICAgICAgR1BBID0gMy44LFxuICAgICAgICAgICAgICAgICAgICAgIHllYXIgPSBcIkp1bmlvclwiKVxuXG4jIENvbWJpbmUgbGlzdFxuY29tYmluZWQgPC0gYyhwZXJzb25hbF9pbmZvLCBhY2FkZW1pY19pbmZvKVxuY29tYmluZWQifQ== Lists provide flexibility in storing and organizing data with different variable types and their versatility ensures we can create custom data structures suited to a specific project’s needs. 2.2.4 Dataframe In R, dataframes are arguably the most essential data structure and the data structure you would likely work with the most. They are like spreadsheets but on steroids! They help you store, organize, manipulate and analyze data way more efficiently than traditional spreadsheets. Dataframes are two dimensional tables consisting of rows and columns. They are somewhat akin to matrices but dataframes have the added ability to store diverse data types. Columns can hold different data types from text, numbers, dates, etc. Unlike matrices, dataframes have named columns, with each column having a unique name for easy identification and access. Dataframes combine the flexibility of other data structures into one and simplify data manipulation, making them extremely efficient. It is from dataframes that you can perform groupings and filtering based on specific criteria, perform statistical computing tasks like calculations, machine learning, etc., and generate plots from their data as well as integrate seamlessly with a host of R functions tailored for manipulation, analysis and modeling. If you work in R, you would likely be doing more importing than creation of dataframes but nonetheless, we will discuss how they can be created as sometimes it is necessary to reproduce portions of your code for troubleshooting in case you run into errors or experience bugs. Creating a dataframe can be done in 3 ways. You can import it, create it from scratch using the data.frame() function with named vectors for each column or transform existing data structures like matrices, lists or, you guessed it, vectors into dataframes. Let us say we want to create a dataframe of Friends’ characters, where we store each friend’s name, phone number, address and age. We can do it like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0aW5nIGEgZGF0YWZyYW1lIHdpdGggY2hhcmFjdGVycyBmcm9tIFwiRnJpZW5kc1wiXG5mcmllbmRzX2NoYXJhY3RlcnMgPC0gZGF0YS5mcmFtZShcbiAgbmFtZSA9IGMoXCJSYWNoZWwgR3JlZW5cIiwgXCJSb3NzIEdlbGxlclwiLCBcIk1vbmljYSBHZWxsZXJcIixcbiAgICAgICAgICAgXCJDaGFuZGxlciBCaW5nXCIsIFwiSm9leSBUcmliYmlhbmlcIiwgXCJQaG9lYmUgQnVmZmF5XCIpLFxuICBwaG9uZV9udW1iZXIgPSBjKFwiNTU1LTExMTFcIiwgXCI1NTUtMjIyMlwiLCBcIjU1NS0zMzMzXCIsIFwiNTU1LTQ0NDRcIixcbiAgICAgICAgICAgICAgICAgICBcIjU1NS01NTU1XCIsIFwiNTU1LTY2NjZcIiksXG4gIGFkZHJlc3MgPSBjKFwiOTAgQmVkZm9yZCBTdCwgTmV3IFlvcmssIE5ZXCIsIFwiOTAgQmVkZm9yZCBTdCwgTmV3IFlvcmssIE5ZXCIsXG4gICAgICAgICAgICAgIFwiOTAgQmVkZm9yZCBTdCwgTmV3IFlvcmssIE5ZXCIsIFwiOTAgQmVkZm9yZCBTdCwgTmV3IFlvcmssIE5ZXCIsXG4gICAgICAgICAgICAgIFwiOTAgQmVkZm9yZCBTdCwgTmV3IFlvcmssIE5ZXCIsIFwiOTAgQmVkZm9yZCBTdCwgTmV3IFlvcmssIE5ZXCIpLFxuICBBZ2UgPSBjKDMwLCAzMiwgMjgsIDI5LCAyNywgMzEpXG4pXG5cbiMgUHJpbnQgdGhlIGRhdGFmcmFtZVxuZnJpZW5kc19jaGFyYWN0ZXJzIn0= You can also import a dataset using R’s read.csv() function that allows you to import a file from your project directory or from a URL. Check out more here We will dedicate a special section to talk about subsetting in the subesquent paragraphs but first we will talk about basic data operations with datframes. We can do a host of dataframe operations but the most relevant ones for this stage of this course are: Subsetting and filtering Adding and removing columns Merging dataframes Aggregation Visualization 2.2.4.0.1 Subsetting &amp; Filtering Do you remember the syntax for installing a package? Install and load the palmerpenguins package and assign the penguins dataset to a variable df. You will see df a lot as it is shorthand for dataframe. Since we are working on a web version of R however, we would have to import the dataframe from a URL. Let me show a neat little trick in RStudio. To do this in one line, you can use this if you have the palmerpenguins dataset installed already. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgYW5kIGFzc2lnbiBwZW5ndWlucyBkYXRhc2V0IHRvIGRmXG5saWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG5kZiA8LSBwZW5ndWlucyJ9 Subsetting a dataframe is relatively straightforward and alike subsetting a matrix. There are numerous packages that make subsetting very easy but it is important to understand the default way so you can troubleshoot errors on your own. The syntax for subsetting a dataframe in R is df[rows, columns]. You can subset also for a single row or column. Let us dive in: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIEluIFIgd2UgdXNlIGhlYWQoKSB0byBwcmV2aWV3IGEgZGF0YXNldFxuaGVhZChkZikifQ== To extract only the first row of a dataset along with all columns, you can do this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFJldHVybiByb3cgMSBvZiB0aGUgcGVuZ3VpbnMgZGF0YXNldFxuZGZbMSwgXSJ9 You can decide to index all rows of the second column like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFN1YnNldCBmb3IgY29sdW1uIDJcbmRmWywgMl0ifQ== Remember the : operator? You can supply it to an index to specify a range of columns or rows you want to extract like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFN1YnNldCBmb3Igcm93cyAxIHRvIDUgb2YgdGhlIGZsaXBwZXIgbGVuZ3RoIGNvbHVtblxuZGZbMTo1LCA1XSJ9 You can subset both specified range of rows and columns like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFN1YnNldCBmb3Igcm93cyA3IHRvIDEyIGFuZCBzcGVjaWVzLCBpc2xhbmQgYW5kIGJpbGwgbGVuZ3RoIGNvbHVtbnNcbmRmWzc6MTIsIGMoMTozKV0ifQ== Load the iris dataset and extract all columns of rows 15 to 30 below eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgaXJpcyBkYXRhc2V0XG5cblxuIyBTdWJzZXQgYWxsIGNvbHVtbnMgb2Ygcm93cyAxNSB0byAzMCIsInNvbHV0aW9uIjoiIyBMb2FkIGlyaXMgZGF0YXNldFxuaXJpcyA8LSBkYXRhc2V0czo6aXJpc1xuXG4jIFN1YnNldCBhbGwgY29sdW1ucyBvZiByb3dzIDE1IHRvIDMwXG5pcmlzX3N1YnNldCA8LSBpcmlzWzE1OjMwLCBdXG5cbmlyaXNfc3Vic2V0In0= We can also subset my explicitly calling the function called subset. We will talk about a more advanced way of subsetting and filtering dataframes using the square brackets we talked about after. To subset our dataframe, df for only the Chinstrap penguins, we can do so like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFN1YnNldCBkYXRhZnJhbWUgdG8gcmV0dXJuIG9ubHkgdGhlIENoaW5zdHJhcCBwZW5ndWluIHNwZWNpZXNcbmNoaW5zdHJhcF9wZW5ndWlucyA8LSBzdWJzZXQoZGYsIHNwZWNpZXMgPT0gXCJDaGluc3RyYXBcIilcblxuIyBQcmV2aWV3IGNoaW5zdHJhcF9wZW5ndWlucyBkYXRhZnJhbWVcbmhlYWQoY2hpbnN0cmFwX3Blbmd1aW5zKVxuXG5ucm93KGRmKVxubnJvdyhjaGluc3RyYXBfcGVuZ3VpbnMpIn0= You can see here that we returned a dataframe containing only the chinstrap penguin species. Can you subset the penguins dataset to return only rows containing the Adelie penguin species? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgcGVuZ3VpbnMgZGF0YXNldFxuXG4jIFN1YnNldCBvbmx5IEFkZWxpZSBzcGVjaWVzIiwic29sdXRpb24iOiIjIExvYWQgcGVuZ3VpbnMgZGF0YXNldFxucGVuZ3VpbnMgPC0gcGFsbWVycGVuZ3VpbnM6OnBlbmd1aW5zXG5cbiMgU3Vic2V0IG9ubHkgQWRlbGllIHNwZWNpZXNcbmFkZWxpZV9wZW5ndWlucyA8LSBzdWJzZXQocGVuZ3VpbnMsIHNwZWNpZXMgPT0gXCJBZGVsaWVcIilcbmFkZWxpZV9wZW5ndWlucyJ9 Usually the subsetted or filtered dataframe should have fewer rows than the original dataframe and you can check the number of rows by using R’s nrow() function. Now, back to our original subsetting technique using square brackets. We can do the same thing using the basic bracket notation subsetting. Say we wanted to return a dataframe of penguins that were on the Biscoe island, we can do that like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFJldHVybiBhIGRhdGFmcmFtZSB0aGF0IGNvbnRhaW5zIG9ubHkgcGVuZ3VpbnMgb24gdGhlIEJpc2NvZSBpc2xhbmRcbmJpY29lX2lzbGFuZCA8LSBkZltkZiRpc2xhbmQgPT0gXCJCaXNjb2VcIiwgXVxuXG4jIFByaW50IHJlc3VsdGluZyBkYXRhZnJhbWVcbmJpY29lX2lzbGFuZCJ9 You can also negate conditions when using square bracket index notation. For example you can filter the penguins dataframe for all penguins that are not the Adelie species like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFJldHVybiBwZW5ndWlucyB0aGF0IHdlcmUgbm90IEFkZWxpZSBzcGVjaWVzXG5ub25fYWRlbGllIDwtIGRmW2RmJHNwZWNpZXMgIT0gXCJBZGVsaWVcIiwgXVxuXG5ub25fYWRlbGllIn0= You can also subset using logical conditions. For instance, suppose we wanted to filter for heavy penguins, say ones above 5000 grammes, we could do that like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBhbG1lcnBlbmd1aW5zKVxuXG4jIEltcG9ydCBkYXRhc2V0XG5kZiA8LSBwZW5ndWluc1xuXG4jIFJldHVybiBwZW5ndWlucyB0aGF0IGhhZCBhIGJvZHkgbWFzcyBvZiBtb3JlIHRoYW4gNTAwMCBncmFtbWVzXG5oZWF2eV9wZW5ndWlucyA8LSBkZltkZiRib2R5X21hc3NfZyA+IDUwMDAsIF1cblxuaGVhdnlfcGVuZ3VpbnMifQ== Remember that when subsetting with square bracket notation, the first value supplied is the rows. So in all of the subsetting operations we did above, we specified the condition in the first argument, telling R to return only rows that match the condition and then we left the column argument empty to return all columns. A quick tip, if you leave the rows argument blank, you want to return all rows and if you leave the column argument blank, you want to return all columns. Can you load the iris dataset and subset for all flowers that were of the versicolor species? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgaXJpcyBkYXRhc2V0XG5cblxuIyBTdWJzZXQgZm9yIHZlcnNpY29sb3Igc3BlY2llcyIsInNvbHV0aW9uIjoiIyBMb2FkIGlyaXMgZGF0YXNldFxuaXJpcyA8LSBkYXRhc2V0czo6aXJpc1xuXG4jIFN1YnNldCBmb3IgdmVyc2ljb2xvciBzcGVjaWVzXG52ZXJzaWNvbG9yX3NwZWNpZXMgPC0gaXJpc1tpcmlzJFNwZWNpZXMgPT0gXCJ2ZXJzaWNvbG9yXCIsIF1cbnZlcnNpY29sb3Jfc3BlY2llcyJ9 How about filtering for flowers with a sepal length of equal to or more than 7 centimeters? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgaXJpcyBkYXRhc2V0XG5cbiMgU3Vic2V0IGZvciBmbG93ZXJzIHdpdGggc2VwYWwgbGVuZ3RoIGVxdWFsIG9yIGdyZWF0ZXIgdGhhbiA3Y20iLCJzb2x1dGlvbiI6IiMgTG9hZCBpcmlzIGRhdGFzZXRcbmlyaXMgPC0gZGF0YXNldHM6OmlyaXNcblxuIyBTdWJzZXQgZm9yIGZsb3dlcnMgd2l0aCBzZXBhbCBsZW5ndGggZXF1YWwgb3IgZ3JlYXRlciB0aGFuIDdjbVxubG9uZ19zZXBhbHMgPC0gaXJpc1tpcmlzJFNlcGFsLkxlbmd0aCA+PSA3XVxubG9uZ19zZXBhbHMifQ== We have looked at the subsetting dataframes in R and at this point, we would like to point out that, in R, we can apply further operations to dataframes. We can find average, length of a column, minimum and maximum values as well as standard deviation of columns. Let us look at these individually. To find the mean, you can just call the function mean() on a numeric/integer column in a dataframe to return the average value in that column. Before we do that, we would like to introduce a very important operator known as the dollar sign operator $. This operator is used to access a specific column within a dataframe. To find the mean of say the flipper length column in our dataframe, we can do this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBkYXRhc2V0XG4jZGYgPC0gcmVhZC5jc3YoJycpXG5cbiMgRmluZCBtZWFuIG9mIGZsaXBwZXIgbGVuZ3RoIGNvbHVtblxubWVhbihkZiRmbGlwcGVyX2xlbmd0aF9tbSwgbmEucm0gPSBUKSJ9 Noticed we introduced an na.rm argument to the mean function? This argument tells the mean function that, any missing values in our dataset should be removed before performing the operation. This is usually used when you have some rows that have missing data, which is true in our case. If your dataframe column you want to perform an operation on does not have any missing values, you can remove this argument completely. Our average flipper length is 200.9152 mm. Apart from mean, we can also find the number of elements in a dataframe column using the length() function. This function can also be applied to vectors but we will talk about its specific use case for dataframes. Say we want to find out the number of values in our species column. We can do that like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBkYXRhc2V0XG4jZGYgPC0gcmVhZC5jc3YoJycpXG5cbiMgRmluZCBsZW5ndGggb2Ygc3BlY2llcyBjb2x1bW5cbmxlbmd0aChkZiRzcGVjaWVzKSJ9 Voilà! We have 344 elements in our species column. What if we want to find the maximum and minimum values in a column? we can use the max() and min() functions respectively. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBkYXRhc2V0XG4jZGYgPC0gcmVhZC5jc3YoJycpXG5cbiMgRmluZCBtYXhpbXVtIGFuZCBtaW5pbXVtIGJvZHkgbWFzcyBpbiBkZlxubWF4KGRmJGJvZHlfbWFzc19nKVxubWluKGRmJGJvZHlfbWFzc19nKSJ9 This returns NA for each? Can you tell why? In our dataframe, we have missing entries for some rows. To solve that, we use the na.rm = TRUE to resolve this error. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBkYXRhc2V0XG4jZGYgPC0gcmVhZC5jc3YoJycpXG5cbiMgRmluZCBtYXhpbXVtIGFuZCBtaW5pbXVtIGJvZHkgbWFzcyBpbiBkZlxubWF4KGRmJGJvZHlfbWFzc19nLCBuYS5ybSA9IFRSVUUpXG5taW4oZGYkYm9keV9tYXNzX2csIG5hLnJtID0gVFJVRSkifQ== Perfect! The heaviest penguin weighed 6,300 grammes and the lightest penguin weighed 2,700 grammes. Sometimes, we would also like to find the standard deviation of values in a column. in R, we can use the sd() function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBkYXRhc2V0XG4jZGYgPC0gcmVhZC5jc3YoJycpXG5cbiMgRmluZCB0aGUgc3RhbmRhcmQgZGV2aWF0aW9uIG9mIGJpbGwgZGVwdGhzXG5zZChkZiRiaWxsX2RlcHRoX21tLCBuYS5ybSA9IFRSVUUpIn0= The standard deviation of bill depths was 1.974793 mm! There are more functions but we will introduce one last one here called sum() which is used to sum up the values in a column. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBkYXRhc2V0XG4jZGYgPC0gcmVhZC5jc3YoJycpXG5cbiMgRmluZCB0aGUgc3VtIG9mIGFsbCBiaWxsIGxlbmd0aHNcbnN1bShkZiRiaWxsX2xlbmd0aF9tbSwgbmEucm0gPSBUUlVFKSJ9 The sum of all bill lengths was 15,021.3 mm. 2.2.5 Factor The last data structure we would look at in this chapter is the factor. Factors are special data structures in R specifically designed to handle categorical data. Categorical data in R refers to variables that can take a set of values representing distinct groups, or to be more implicit, categories. Inherently, factors are integers as each category is assigned a unique integer value but are displayed as their corresponding label. Each factor has levels and can be ordered or unordered. 2.2.5.1 Creating a factor You would find yourself converting dataframe columns to factors more than creating them from scratch but the syntax to do so is basic and a factor can be created like this using the factor() function: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGJhc2ljIGZhY3RvclxuZmFjb3JfZXhhbXBsZSA8LSBmYWN0b3IoYyhcIkFcIiwgXCJCXCIsIFwiQVwiLCBcIkNcIiwgXCJCXCIpKVxuXG5cbiMgQ3JlYXRlIGEgZmFjdG9yIHNwZWNpZnlpbmcgbGV2ZWxzXG5mYWN0b3Jfd2l0aF9sZXZlbHMgPC0gZmFjdG9yKGMoXCJoaWdoXCIsXCJsb3dcIiwgXCJsb3dcIiwgXCJtZWRpdW1cIiwgXCJsb3dcIiksXG4gICAgICAgICAgICAgICAgICAgICAgICAgICAgIGxldmVscyA9IGMoXCJoaWdoXCIsIFwibG93XCIsIFwibWVkaXVtXCIpKVxuXG4jIFZpZXcgYSBmYWN0b3JzIGxldmVsc1xubGV2ZWxzKGZhY3Rvcl93aXRoX2xldmVscykifQ== The good thing about factors is that, even after specifying levels in our previous example, you can also create ordered factors. In situations where categories have a natural order or logical progression, factors ca provide additional information to statistical analyses. Creating one is not so different from creating a basic factor. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGZhY3RvciB3aXRoIG9yZGVyZWQgbGV2ZWxzXG5vcmRlcmVkX2ZhY3RvciA8LSBmYWN0b3IoYyhcInNtYWxsXCIsIFwibWVkaXVtXCIsIFwibGFyZ2VcIiwgXCJtZWRpdW1cIiwgXCJzbWFsbFwiKSxcbiAgICAgICAgICAgICAgICAgICAgICAgICBsZXZlbHMgPSBjKFwic21hbGxcIiwgXCJtZWRpdW1cIiwgXCJsYXJnZVwiKSxcbiAgICAgICAgICAgICAgICAgICAgICAgICBvcmRlcmVkID0gVFJVRSlcblxuIyBWaWV3IHRoZSBsZXZlbHMgb2YgdGhlIG9yZGVyZWQgZmFjdG9yXG5sZXZlbHMob3JkZXJlZF9mYWN0b3IpIn0= 2.3 CODE CHALLENGE Create two numeric vectors, vec1 containing elements 8, 5, 10, 50, 3 and vec2 containing 78, 15, 2, 13, 59. Perform element-wise addition and then subtract vec1 from vec2, multiply vec1 and vec2, and divide vec2 by vec1. Store the results in new vectors: addition_vec, subtraction_vec, multiplication_vec and division_vec. You have 6 coworkers: Jim, Pam, Michael, Oscar, Dwight and Stanley. Create a vector called office_buddies and store your coworkers’ names there. After, you create the vector, extract Michael’s name using bracket notation and assign it to a variable named regional_manager Generate a vector named score containing the following scores of students in a test: 15, 25, 8, 39, 4, 45, 33, 31, 49, and 21. These scores were initially marked out of 50. Calculate the percentage score for each student by performing the relevant vector operations on it and store the result to a new vector name score_pct Subset score_pct to return scores over 60%. Using the USArrests dataset, subset for all data where UrbanPop was greater than or equal to 80. Assign the resulting dataframe to high_pop Create a 4x4 matrix, myMatrix with numbers from 1 to 16 and then, extract all elements in the second row and assign to second_row Create a list called my_list containing elements: apple, mango, 56.9, TRUE, tropical, 35 and FALSE. Retrieve the last element in the list Add a new element to your list called Jamaica Remove the fourth element in the list. Return the length of your list Using the trees dataset, subset for all rows and columns for trees with a girth greater than 15. Assign the new dataframe to girth_15 Create a list called real_madrid with elements representing the club’s stadium: Santiago Bernabéu, the city: Madrid, the year it was founded: 1902 and the league: La Liga. Also add the a logical value true or false, indicating if you like Real Madrid and assign that to is_liked Using the jobs_in_data.csv file as your dataframe: Import the dataframe and assign to a variable called df Subset the first 5 rows of all columns in your dataframe and assign to first_five Filter the dataset to return all rows and all columns where the job title is a Data Analyst and assign to data_analysts_df Return the average salary for all data analysts and assign to avg_salary Create a numeric vector, numbers, with values from 1 to 20. Calculate the mean of the vector and assign to avg_num Square each element of the vector and assign to squared_num Find the maximum value in the modified vector and assign to highest_val "],["data-import.html", "Chapter 3 DATA IMPORT 3.1 THE WORKING DIRECTORY 3.2 IMPORTING DATA INTO R 3.3 DATA FROM SOME STATISTICAL PACKAGES INTO R 3.4 Data EXPORT 3.5 OTHER DATA FORMATS 3.6 ASSIGNMENT", " Chapter 3 DATA IMPORT 3.1 THE WORKING DIRECTORY In R, a working directory is the default location where R looks for files you load, save and/or access without providing a full path. It is like your home base for all file operations within R. R uses file paths to locate files on your computer’s file system. In R, you can use an absolute or relative path to specify a working directory. If you are a bit familiar with bash, a relative path is the path relative to your working directory. For example if you set your working directory to a folder called project, to load a dataset called quarterly_sales.csv in a subfolder called data for example, the relative path would be project/data/quarterly_sales.csv. The absolute path could be something like this: C:/Users/YourName/Documents/project/data/quarterly_sales.csv Working in RStudio, file systems can be a bit of a nuisance if you do not correctly set them up. This is why it is recommended to create a project in RStudio whenever you’re working with it as it will minimize your file system headaches a lot. We have already talked about setting up a project in Chapter 1 but, sometimes in R you might want to work without setting up an entire project. In this case, you need to set up a working directory. Why? Setting up a working directory keeps your files organized, ensures portability and overall, makes the overall development experience convenient. 3.1.1 How to setup a working Directory In RStudio, there are three main ways to set up a working directory. You can use the Menu bar, a keyboard shortcut or you can set it programatically. 3.1.1.1 RStudio Menu To set up a working directory, go to the menu bar at the top of your RSTudio window. Go to “Session” &gt; “Set Working Directory” &gt; “Choose Working Directory” Select your desired directory and click “Choose” 3.1.1.2 Keyboard Shortcut For Windows &amp; Linux: Press Ctrl+Shift+H For macOS: Press Cmd+Shift+H 3.1.1.3 Setting Working Directory Programmatically To do this, you can use base R’s setwd() function and supply the file path, whether relative or absolute. Here is an example: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFNldCB3b3JraW5nIGRpcmVjdG9yeVxuI3NldHdkKFwiL3BhdGgvdG8veW91ci9kZXNpcmVkL2RpcmVjdG9yeVwiKSJ9 Where /path/to/your/desired/directory is the actual path you want to set it to. 3.2 IMPORTING DATA INTO R Importing data into R is the process of bringing in data from external sources into R’s environment for further analysis ot manipulation. It is usually the first step in almost every R workflow. 3.2.1 Data Sources R’s prowess is such that, you can import nearly any data file format. From tabular .txt files, .csv, delimited text files, SAS, SPSS, Stata, Excel, JSON and APIs as well as .jpeg, .tiff, Big data and even importing data from databases, R does it all. We talked about the read.csv() function in the previous chapter but that isn’T all. There are numerous functions from various packages to read in data into R, however, there are some default functions that do this. The built-in functions for data import into R are: - read.table(): Reads data from a tabular text file. - read.csv(): Reads data from a CSV file. - read.delim(): Reads data from a delimited text file. - readLines(): Reads lines from a text file. 3.2.2 The Importing Process Importing data into R is quite simple as functions follow similar logic. You will need a file path, the appropriate function and it is usually recommended to assign the imported data to a variable to prevent it from being printed and lost. Following this workflow, we can import a .csv file like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFN5bnRheCBmb3IgaW1wb3J0aW5nIGEgZGF0YXNldFxuI215X2RhdGEgPC0gcmVhZC5jc3YoXCJkYXRhL215X2RhdGEuY3N2XCIpIn0= The line has been commented out because it is used to show the syntax of importing data into R. You will notice we wrapped the file path of the dataset including our dataset name and extension in quotes. This is important as failure to do so will make R interpret is as a variable and throw up an error. We then assigned our imported data to a variable called my_data. 3.2.3 Data Exploration After importing data, R has some built-in functions you can use to inspect your dataframe’s contents and structure. You can use the following functions to achieve this: - View()- opens a spreadsheet-like viewer to explore dataframe interactively - head() - displays first few rows of your dataframe - tail() - just like head, it displays last few rows of your dataframe - str() - stands for structure and it is used to display a compact internal structure of an R object. It usually shows each type of variable in your dataframe, its length and a few values of each variable. 3.3 DATA FROM SOME STATISTICAL PACKAGES INTO R There are a lot of packages that allow imports from data sources into R. To use them, you usually need to install and load them into your R environment before accessing these import functions. Here are some common Data Sources and R Functions to import them with. It is recommended to read the package documentation for specific options or parameters. Text files (CSV, TSV): read.csv(): For comma-separated values read.table(): For more general text files, with options to specify delimiters Excel files: readxl::read_excel(): Requires the readxl package JSON files: jsonlite::fromJSON(): Requires the jsonlite package SQL databases: RSQLite::dbConnect(): For SQLite databases DBI::dbConnect(): For other database types (requires specific database drivers) Statistical packages (SPSS, SAS): foreign::read.spss(): For SPSS files haven::read_sav(): For SAS files (requires the haven package) Web APIs: httr::GET(): To retrieve data from web APIs jsonlite::fromJSON(): To parse JSON responses 3.4 Data EXPORT Just like we can import data into R, R also allows us to export data from R to our local disk or wherever we want to export to. For text files, you can use R’s built-in write.csv() to write a dataframe to a .csv file or write.table() for text files. you can also use saveRDS() to save an R object in R readable format or save() to save multiple objects to an RData file. For other formats like excel files you can use the package writexl to do that by calling write.xlsx() to save a dataframe to an excel sheet. For JSON files, you can use the function toJSON() from jsonlite to write a file to JSON format. 3.4.1 Writing to different formats To export to as a .csv file you use the eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHNhbXBsZSBkYXRhZnJhbWVcbmRmIDwtIGRhdGEuZnJhbWUoXG4gIElEID0gYygxLCAyLCAzLCA0LCA1KSxcbiAgTmFtZSA9IGMoXCJUaG9tYXNcIiwgXCJCb2JcIiwgXCJIZWxlblwiLCBcIkRhdmlkXCIsIFwiRXZhXCIpLFxuICBBZ2UgPSBjKDI1LCAzMCwgMjIsIDM1LCAyOCksXG4gIFNjb3JlID0gYyg5NSwgODUsIDkyLCA4OCwgNzUpXG4pXG5cbiMgWW91IGNhbiBzYXZlIHRvIHlvdXIgcHJvamVjdCBkaXJlY3RvcnkgbGlrZSB0aGlzLiBMaW5lcyBoYXZlIGJlZW4gY29tbWVudGVkXG4jIG91dCBiZWNhdXNlIHdlIGRvIG5vdCBoYXZlIFxuIyB3cml0ZS5jc3YoZGYsIGZpbGUgPSBcIm91dHB1dF9kYXRhLmNzdlwiLCByb3cubmFtZXMgPSBGQUxTRSlcbiMgd3JpdGUudGFibGUoZGYsIGZpbGUgPSBcIm91dHB1dF9kYXRhLnR4dFwiLCBzZXAgPSBcIlxcdFwiLCByb3cubmFtZXMgPSBGQUxTRSlcbiMgd3JpdGVfeGxzeChkZiwgcGF0aCA9IFwib3V0cHV0X2RhdGEueGxzeFwiKVxuXG4jIEZvciBKU09OLCB5b3UgbmVlZCB0byBjb252ZXJ0IHRoZSBkYXRhIHRvIEpTT04gZm9ybWF0IGJlZm9yZSBleHBvcnRpbmcuIFxuIyBqc29uX2RhdGEgPC0gdG9KU09OKGRmLCBwcmV0dHkgPSBUUlVFKVxuIyB3cml0ZUxpbmVzKGpzb25fZGF0YSwgXCJvdXRwdXRfZGF0YS5qc29uXCIpIn0= For JSON objects, it is always recommended to ensure your dataframe is compatible with a JSON format before exporting. 3.5 OTHER DATA FORMATS There are countless other data formats R supports. Usually, as an R programmer, you will have to search for these packages or if you have the skill and there is enough interest, build these packages yourself as R extensions to support data types you want. 3.5.1 Web Scraping An Aspect we would like to briefly touch on is web scraping. Sometimes the data we want are available on websites and not in necessarily ready formats to allow further analysis. This is where web scraping comes in. R’s prowess extends to this domain and allows data from websites to be programmatically extracted into R for further analysis. There are several web scraping packages but the most widely used ones in R are the httr and rvest packages. 3.6 ASSIGNMENT Create a project named pilot in RStudio Use the datasets package to import the chickwts dataset and assign to a variable called df Filter df for only horsebean fed chicks. Use write.csv() to export your dataset to your working directory Run the dir() function and copy its output to a .txt and submit it. "],["descriptive-statistics.html", "Chapter 4 DESCRIPTIVE STATISTICS 4.1 MEASURES OF CENTRAL TENDENCY 4.2 MEASURES OF VARIABILITY 4.3 SKEWNESS AND KURTOSIS 4.4 SUMMARY FUNCTIONS 4.5 CORRELATION 4.6 CODE CHALLENGE", " Chapter 4 DESCRIPTIVE STATISTICS Descriptive statistics in R involve the use of various numerical and graphical methods to summarize and describe the main features of a dataset. These statistics provide a concise overview of the central tendency, dispersion, and shape of the distribution of data. Common measures include the mean, median, and mode for central tendency, while measures such as range, variance, and standard deviation describe the spread or dispersion of the data. Additionally, summary statistics like minimum and maximum values, quartiles, and percentiles help understand the overall distribution. R provides a rich set of functions, including summary(), mean(), median(), sd() (standard deviation), and various quantile functions, to quickly compute and explore these descriptive statistics for a given dataset. Visualization is also a key aspect of descriptive statistics in R. Box plots, histograms, and density plots can be generated to visually represent the distribution of data. Exploring descriptive statistics aids in uncovering patterns, identifying outliers, and gaining a fundamental understanding of the dataset’s characteristics, setting the stage for more advanced statistical analyses. 4.1 MEASURES OF CENTRAL TENDENCY Measures of central tendency, also called, measures of central location are numerical values that summarize a dataset by indicating its central or typical value. The measures of central tendency in R are mainly the mean, the median and the mode. The mean is the average value if you were to distribute the total evenly among all observations The Median represents the middle value with half of the observations below and half above it The Mode is used to identify the most common value, which may highlight potential trends or patterns. In R, using the summary() function summarizes a dataframe. It will return the mean, median, quartiles, minimum and maximum values for each numeric/integer column in your dataset along with indicating if there are missing values in said columns. Let us see the summary() function in action. For this chapter, we will use the mtcars dataset from R’s datasets package eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCB0aGUgbXRjYXJzIGRhdGFzZXRcbmRmIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBTdW1tYXJpemUgdGhlIGRhdGFmcmFtZSB1c2luZyBzdW1tYXJ5XG5zdW1tYXJ5KGRmKSJ9 Simple as that! R summarizes the numeric and integer columns and gives us some descriptive statistics which helps us understand our data before further analysis. 4.1.1 The mean The mean is a measure of central tendency that represents the average value of a set of numbers. It is calculated by adding up all the values in the dataset and then dividing the sum by the total number of values. In simpler terms, it’s the sum of all values divided by the count of values. In R, you can calculate the mean of a set of numbers like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG51bWVyaWMgdmVjdG9yXG5udW1lcmljX3ZlY3RvciA8LSBjKDEwLCAxNSwgMjAsIDI1LCAzMClcblxuIyBDYWxjdWxhdGUgdGhlIG1lYW4gdXNpbmcgdGhlIG1lYW4oKSBmdW5jdGlvblxubWVhbl92YWx1ZSA8LSBtZWFuKG51bWVyaWNfdmVjdG9yKVxuXG4jIFByaW50IHRoZSByZXN1bHRcbm1lYW5fdmFsdWUifQ== 4.1.1.1 Handling Missing Values The mean() function in R has an argument called na.rm (NA remove) that is set to FALSE by default. This means that if there are any missing values (NAs) in your data, the result of running the mean function will be NA. If you want to exclude missing values from the calculation, you can set na.rm = TRUE. Here is an example eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHZlY3RvciB3aXRoIG1pc3NpbmcgdmFsdWVzXG52ZWN0b3Jfd2l0aF9uYSA8LSBjKDEwLCAxNSwgTkEsIDI1LCAzMClcblxuIyBDYWxjdWxhdGUgdGhlIG1lYW4sIGV4Y2x1ZGluZyBtaXNzaW5nIHZhbHVlc1xubWVhbl92YWx1ZV93aXRob3V0X25hIDwtIG1lYW4odmVjdG9yX3dpdGhfbmEsIG5hLnJtID0gVFJVRSlcblxuIyBQcmludCB0aGUgcmVzdWx0XG5tZWFuX3ZhbHVlX3dpdGhvdXRfbmEifQ== 4.1.2 The median The median is the middle value in a sorted set of values. To calculate the median in R, you can use the median() function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEV4YW1wbGUgd2l0aCBhIG51bWVyaWMgdmVjdG9yXG5udW1lcmljX3ZlY3RvciA8LSBjKDEsIDIsIDMsIDQsIDUpXG5cbm1lZGlhbl92YWx1ZSA8LSBtZWRpYW4obnVtZXJpY192ZWN0b3IpXG5cbnByaW50KG1lZGlhbl92YWx1ZSkifQ== You can also find the median of a numeric or integer column of a dataframe like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEV4YW1wbGUgd2l0aCBhIGRhdGEgZnJhbWVcbmRhdGEgPC0gZGF0YS5mcmFtZShOYW1lID0gYyhcIkFsaWNlXCIsIFwiQm9iXCIsIFwiQnJhZFwiLCBcIkNoYXJsaWVcIiwgXCJDaGFybG90dGVcIixcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICBcIkRhdmlkXCIsIFwiRGFuaWVsYVwiKSxcbiAgICAgICAgICAgICAgICAgICBBZ2UgPSBjKDI1LCA1MCwgNDQsIDIwLCAyMiwgMjgsIDE3KSlcblxubWVkaWFuX2FnZSA8LSBtZWRpYW4oZGF0YSRBZ2UpXG5cbnByaW50KG1lZGlhbl9hZ2UpIn0= Load the mtcars dataset and find the median cylinder value as well as the mean horsepower in that dataset below eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5cbiMgQ2FsY3VsYXRlIGFuZCBwcmludCBtZWRpYW4gb2YgY3lsaW5kZXJzXG5cblxuIyBDYWxjdWxhdGUgYW5kIHByaW50IGF2ZXJhZ2UgaG9yc2Vwb3dlciIsInNvbHV0aW9uIjoiIyBMb2FkIG10Y2Fyc1xubXRjYXJzIDwtZGF0YXNldHM6Om10Y2Fyc1xuXG4jIENhbGN1bGF0ZSBtZWRpYW4gb2YgY3lsaW5kZXJzXG5tZWRfY3lsaW5kZXJzIDwtIG1lZGlhbihtdGNhcnMkY3lsKVxubWVkX2N5bGluZGVyc1xuXG4jIENhbGN1bGF0ZSBhdmVyYWdlIGhvcnNlcG93ZXJcbmF2Z19ocCA8LSBtZWFuKG10Y2FycyRocClcbmF2Z19ocCJ9 4.2 MEASURES OF VARIABILITY Also known as measures of dispersion, measures of variability tells us how spread out the data is in a dataset. In other words, these statistics quantify how much individual data points in a distribution deviate from the central tendency. This information is crucial for understanding our data’s nature and helps in drawing accurate conclusions from our analysis The key measures of variability in R are - Range - Interquartile Range (IQR) - Variance - Standard Deviation 4.2.1 Range Range is the simplest measure of variability. It is usually calculated as the difference between the largest and smallest values in a dataset. Range is relatively easy to understand and straightforward but a huge issue with it is that, it is very sensitive to outliers and does not tell much about the distribution of the data between. In R, we can use the min and max functions to find the highest and lowest values but R has a built-in range() function that returns the range of given distribution For example, let us use a vector to illustrate how this works. Do note that you can also use the range function on a column in a dataframe but we will use a vector here for simple illustration. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEdlbmVyYXRlIGEgdmVjdG9yXG5kYXRhIDwtIGMoMTAsIDUsIDgsIDEyLCAxNSwgOCwgOClcblxuIyBDYWxsIHRoZSByYW5nZSBmdW5jdGlvblxucmFuZ2UoZGF0YSkifQ== The range of this given distribution is 5, the lowest value and 15, the highest value. Can you calculate the range of bill lengths in the penguins dataset below? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBwZW5ndWlucyBkYXRhc2V0XG5wZW5ndWlucyA8LSBwYWxtZXJwZW5ndWluczo6cGVuZ3VpbnNcblxuIyBDYWxsIHRoZSByYW5nZSBmdW5jdGlvbiBvbiB0aGUgYmlsbCBsZW5ndGggY29sdW1uIiwic29sdXRpb24iOiIjIEltcG9ydCBwZW5ndWlucyBkYXRhc2V0XG5wZW5ndWlucyA8LSBwYWxtZXJwZW5ndWluczo6cGVuZ3VpbnNcblxuIyBDYWxsIHRoZSByYW5nZSBmdW5jdGlvbiBvbiB0aGUgYmlsbCBsZW5ndGggY29sdW1uXG5yYW5nZShwZW5ndWlucyRiaWxsX2xlbmd0aF9tbSxuYS5ybSA9IFRSVUUpIn0= 4.2.2 Interquartile Range (IQR) This divides our data into 4 quartiles, with the IQR representing the range between the first and third quartiles (Q1 and Q3). The interquartile range is less sensitive to outliers than the range and provides information about the central 50% of a data’s distribution. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEdlbmVyYXRlIGEgdmVjdG9yXG5kYXRhIDwtIGMoMTAsIDUsIDgsIDEyLCAxNSwgOCwgOClcblxuIyBDYWxsIHRoZSBJUVIgZnVuY3Rpb25cbklRUihkYXRhKVxuXG4jIENhbGwgdGhlIHF1YW50aWxlIGZ1bmN0aW9uXG5xdWFudGlsZShkYXRhKSJ9 4.2.3 Variance Variance is the average squared distance of each data point from the mean. To calculate it, we use the var() function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEdlbmVyYXRlIGEgdmVjdG9yXG5kYXRhIDwtIGMoMTAsIDUsIDgsIDEyLCAxNSwgOCwgOClcblxuIyBDYWxsIHZhciBmdW5jdGlvblxudmFyKGRhdGEpIn0= 4.2.4 Standard Deviation Standard deviation is the square root of the variance which represents the typical distance of data points from the mean in the units of the original data. To calculate this we use the sd() function in R eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEdlbmVyYXRlIGEgdmVjdG9yXG5kYXRhIDwtIGMoMTAsIDUsIDgsIDEyLCAxNSwgOCwgOClcblxuIyBGaW5kIHN0YW5kYXJkIGRldmlhdGlvblxuc2QoZGF0YSkifQ== Find the standard deviation of the body mass of the penguins in the palmerpenguins dataset eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEltcG9ydCBwZW5ndWlucyBkYXRhc2V0XG5cbiMgQ2FsbCB0aGUgc3RhbmRhcmQgZGV2aWF0aW9uIGZ1bmN0aW9uIG9uIHRoZSBiaWxsIGxlbmd0aCBjb2x1bW4uIiwic29sdXRpb24iOiIjIEltcG9ydCBwZW5ndWlucyBkYXRhc2V0XG5wZW5ndWlucyA8LSBwYWxtZXJwZW5ndWluczo6cGVuZ3VpbnNcblxuIyBDYWxsIHRoZSBzdGFuZGFyZCBkZXZpYXRpb24gZnVuY3Rpb24gb24gdGhlIGJpbGwgbGVuZ3RoIGNvbHVtbi5cbnNkKHBlbmd1aW5zJGJpbGxfbGVuZ3RoX21tLCBuYS5ybSA9IFRSVUUpIn0= You might be wondering why these functions work on vectors but also on dataframe columns like above. The reason is that, these functions are built to operate seamlessly on both individual vectors and dataframe columns. They are perfect for vectors, but when you reference a specific column in a dataframe and apply these functions, R treats that column as a vector in the background. This underlying treatment as a vector allows the functions to work effortlessly on dataframe columns as well. 4.2.5 Factors for Choosing an Appropriate Measure Shape of distribution: for normal distributions, all measures correlate well. For skewed distributions, IQR and SD may be more informative. Presence of outliers: IQR and SD are more robust to outliers than range and variance. Interpretability: SD is easier to understand in the context of the original data units. 4.3 SKEWNESS AND KURTOSIS Skewness and kurtosis are two important quantitative measures used in statistics and data analysis to describe the shape of a distribution. They provide crucial information beyond just the central tendency (e.g., mean, median) of a dataset. 4.3.1 Skewness Skewness measures the asymmetry of a probability distribution. It indicates whether the data is skewed to the left or right of the mean. Skewness can be positive, negative or zero. When a distribution is said to be positively skewed, a visualization of the distribution of its values will have a long tail to the right, indicating the right side has few but larger values. In a positively skewed distribution, the mean is typically greater than the median. When a distribution is said to be negatively skewed however, it has a long tail to the left, indicating few but smaller values. The mean is typically less than the median in a negatively skewed distribution. A distribution is considered symmetric if it has zero skewness, that is, the tails on both sides of the mean are of equal length and the distribution appears roughly symmetrical. In R, you can calculate skewness using the skewness() function from the e1071 package or the skewness() function from the moments package. Here’s an example using the e1071 package: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIHRoZSBlMTA3MSBwYWNrYWdlXG4jaW5zdGFsbC5wYWNrYWdlcyhcImUxMDcxXCIpXG5cbiMgTG9hZCB0aGUgZTEwNzEgcGFja2FnZVxubGlicmFyeShlMTA3MSlcblxuIyBDcmVhdGUgYSBudW1lcmljIHZlY3RvciAocmVwbGFjZSB0aGlzIHdpdGggeW91ciBvd24gZGF0YSlcbmRhdGEgPC0gYygxMCwgNSwgOCwgMTIsIDE1LCA4LCA4KVxuXG4jIENhbGN1bGF0ZSBza2V3bmVzc1xuc2tld25lc3NfdmFsdWUgPC0gc2tld25lc3MoZGF0YSlcblxuIyBQcmludCB0aGUgc2tld25lc3MgdmFsdWVcbnByaW50KHNrZXduZXNzX3ZhbHVlKSJ9 We can conclude that our data is positively skewed. 4.3.2 Kurtosis Kurtosis is a statistical measure that describes the distribution of data in terms of the tails and the peakedness or flatness of the distribution. It provides insights into whether the data has heavy tails or is more concentrated around the mean compared to a normal distribution. Kurtosis complements skewness, which measures the asymmetry of the distribution. There are three main types of kurtosis: Mesokurtic (Normal Distribution): A distribution with kurtosis equal to zero is considered mesokurtic. It has tails and a peak similar to the normal distribution. Leptokurtic (Positive Kurtosis): A distribution with positive kurtosis has heavier tails and a more peaked center compared to a normal distribution. It indicates that the data has more extreme values, and the distribution has fatter tails. 3.Platykurtic (Negative Kurtosis): A distribution with negative kurtosis has lighter tails and is less peaked than a normal distribution. It suggests that the data has fewer extreme values, and the distribution is more spread out. In R, the kurtosis of a dataset can be calculated using the kurtosis() function from the moments package or the kurtosis() function from the e1071 package. These functions provide a numerical measure of kurtosis, which help in assessing the shape of a distribution. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIHRoZSBtb21lbnRzIHBhY2thZ2VcbiMgaW5zdGFsbC5wYWNrYWdlcyhcIm1vbWVudHNcIilcblxuIyBMb2FkIHBhY2thZ2VcbmxpYnJhcnkobW9tZW50cylcbmRhdGEgPC0gYygxLCAyLCAyLCAzLCAzLCAzLCA0LCA0LCA0LCA0KVxuXG5rdXJ0b3Npc192YWx1ZSA8LSBrdXJ0b3NpcyhkYXRhKVxuXG4jIFByaW50IG91dCB2YWx1ZVxua3VydG9zaXNfdmFsdWUifQ== In this case we can conclude the data’s distribution is leptokurtic. 4.4 SUMMARY FUNCTIONS Summary functions and describe functions in R are essential tools for generating descriptive statistics, providing quick insights into the nature of your data. Here’s a breakdown of key functions and considerations: Base R Summary Functions summary() - Offers a basic summary of various data types: - Numeric: Min, max, median, quartiles, mean. - Factor: Number of levels, counts per level. - Character: Length of each string. str() - Displays the internal structure of an object: - Data type, number of elements, first few values. Additional Descriptive Statistics Packages: psych package - describe(): Provides a comprehensive overview of descriptive statistics, including skewness and kurtosis. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIHRoZSBwc3ljaCBwYWNrYWdlXG4jaW5zdGFsbC5wYWNrYWdlcyhcInBzeWNoXCIpXG5cbiMgTG9hZCBwYWNrYWdlXG5saWJyYXJ5KHBzeWNoKVxuXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBDYWxsIGRlc2NyaWJlXG5kZXNjcmliZShjYXJzKSJ9 Hmisc package describe(): Offers similar descriptive statistics with formatting options. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIHRoZSBIbWlzYyBwYWNrYWdlXG4jaW5zdGFsbC5wYWNrYWdlcyhcIm1pc2NcIilcblxuIyBMb2FkIHBhY2thZ2VcbmxpYnJhcnkoSG1pc2MpXG5cbiMgSW1wb3J0IGNhcnMgZGF0YVxuY2FycyA8LSBkYXRhc2V0czo6bXRjYXJzXG5cbkhtaXNjOjpkZXNjcmliZShjYXJzKSJ9 4.4.1 Key Considerations for Using Summary Functions Data type: The type of summary statistics provided depends on the data type (numeric, factor, character). Customization: Some functions allow customization of output and formatting. Exploration: Use these functions in conjunction with visualizations (e.g., histograms, boxplots) for a deeper understanding of your data. Remember: - Summary and describe functions are invaluable for initial data exploration and analysis. - Choose functions and packages that best suit your data types and analysis needs. - Integrate these functions with visualizations for a comprehensive view of your data’s characteristics. 4.5 CORRELATION Correlations are valuable tools in statistics and data analysis, helping us discover relationships between variables. They quantify the degree of association between two variables, revealing if they tend to move together (positive correlation), move in opposite directions (negative correlation), or have no meaningful relationship (zero correlation). 4.5.1 Interpreting Correlations Correlation coefficient values: Range from -1 (perfect negative correlation) to 1 (perfect positive correlation), with 0 indicating no linear relationship. Strength of association: Consider the absolute value of the coefficient: Strong: &gt; 0.7 Moderate: 0.3-0.7 Weak: &lt; 0.3 Direction of association: Positive values indicate variables tend to increase together, while negative values show they tend to decrease together. Causality vs. correlation: Correlation does not imply causation! Just because two variables are associated doesn’t mean one causes the other. Visualizing Correlations: - Scatter plots: Plot one variable on the x-axis and the other on the y-axis to assess the direction and strength of the relationship visually. - Correlation matrices: Display correlations between all pairs of variables in a data frame as a heatmap, showcasing potential patterns and clusters. 4.5.2 Common Mistakes Assuming causality: Always consider other factors and research theories before concluding one variable causes another. Ignoring non-linear relationships: Pearson correlation assumes linearity; for non-linear relationships, consider Spearman rank correlation or other alternatives. Focusing only on statistical significance: Even statistically significant correlations may not be practically meaningful for your research question. 4.5.3 Calculating Correlations in R: Base R function: cor() calculates the Pearson correlation coefficient, which measures linear relationships between continuous variables. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG4jY2FycyA8LSByZWFkLmNzdignKVxuXG4jIFByZXZpZXcgY29sdW1uc1xuaGVhZChjYXJzKVxuXG4jIENoZWNrIGNvcnJlbGF0aW9uIGJldHdlZW4gbXBnIGFuZCBocFxuY29yKGNhcnMkbXBnLCBjYXJzJGhwKSJ9 The correlation value between miles per gallon and horsepower is -0.7761684, indicating a strong negative correlation between miles per gallon and horsepower which can be interpreted as, cars with a higher horsepower or more powerful engines, tend to have lower fuel efficiency and vice versa. We can visualize this using a scatterplot like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBQbG90IGEgc2NhdHRlcnBsb3Qgb2YgbXBnIHZzIGhwXG5wbG90KGNhcnMkaHAsIGNhcnMkbXBnLCBcbiAgICAgbWFpbiA9IFwiU2NhdHRlcnBsb3Qgb2YgaHAgdnMgbXBnXCIsXG4gICAgIHhsYWIgPSBcIkhvcnNlcG93ZXIgKGhwKVwiLFxuICAgICB5bGFiID0gXCJNaWxlcyBwZXIgR2FsbG9uIChtcGcpXCIsXG4gICAgIHBjaCA9IDE2LFxuICAgICBjb2wgPSBcImRvZGdlcmJsdWVcIlxuKSJ9 The scatterplot helps us further see how negatively correlated the two variables are. We will talk about plots in the next chapter Alternatives to calculating correlation in R - Hmisc::rcorr() calculates Pearson and Spearman rank correlations for all pairs of variables in a data frame. - psych::corr.test() provides correlation coefficients alongside significance tests. 4.6 CODE CHALLENGE Using the used car price dataset, find the highest and lowest seats in our dataset and assign highest to max_seats and min_seats. Return the variance and standard deviation of mileage in our dataset. Assign your results to mileage_var and mileage_sd respectively. Check for skewness for mileage in our dataset and if the data is positively skewed, assign “positively skewed” to the variable is_skewed if the data is positively skewed, assign “negatively skewed” to the variable is_skewed if it is symmetric, assign “symmetric” to the variable is_skewed Check for correlation between number of seats and mileage if positively correlated, assign “correlated” to is_correlated if negatively correlated, assign “not correlated” to is_correlated Using the avocado dataset in the datasets folder, check for skewness in average avocado prices. if the data is positively skewed, assign “positively skewed” to the variable is_skewed if the data is positively skewed, assign “negatively skewed” to the variable is_skewed if it is symmetric, assign “symmetric” to the variable is_skewed Find the range of total volume of all avocados and assign to volume_range. Report on the standard deviation and variance of the total bags column. For standard deviation assign your result to tot_bags_sd and for variance, assign it to tot_bags_sd Find the IQR, median and mean of extra large bags of avocados, assigning your results to xl_bags_iqr, xl_bags_median and xl_bags_avg Using the starbucks dataset, return the average calories of beverages that were Caffè Latte and assign your result to latte_avg For all Classic Espresso Drinks in the beverage category, find the standard deviation of total fat they contained and assign to total_fat_sd. "],["graphs.html", "Chapter 5 GRAPHS 5.1 GRAPHING/VISUALIZATION WITH DIFFERENT PACKAGES 5.2 Data Visualization Examples 5.3 WHICH VISUALIZATION PACKAGE TO USE? 5.4 CODE CHALLENGE", " Chapter 5 GRAPHS Drawing graphs is a fundamental and powerful tool in data analysis and visualization, enabling the representation of complex relationships and patterns within datasets. Graphs provide a visual means of conveying information, making it easier for individuals to interpret and understand trends, comparisons, and distributions. Whether creating scatter plots, bar charts, line graphs, or more sophisticated visualizations, the process of drawing graphs allows analysts to communicate insights effectively and facilitates the exploration of data structures. In various fields, from scientific research to business analytics, the art of drawing graphs plays a pivotal role in transforming raw data into actionable insights, supporting evidence-based decision-making and effective communication of findings to diverse audiences. 5.1 GRAPHING/VISUALIZATION WITH DIFFERENT PACKAGES There are countless visualization packages in R however, some of the most popular ones include: Base R Graphics: Built-in functions like plot(), hist(), boxplot(), and barplot() offer basic visualizations. Simple to use but limited customization options. Suitable for quick exploratory plots or basic reports. ggplot2: The king of R visualization! A layered grammar-based approach, providing incredible flexibility and control over every aspect of the plot. Endless possibilities for creating publication-quality graphics with diverse themes and data transformations. Requires some learning curve but offers immense rewards. lattice: Offers a powerful framework for creating multi-panel lattice plots and trellis plots. Useful for comparing several groups or variables within a single graphic. More complex than base R graphics but less demanding than ggplot2 for certain types of visualizations. plotly: Creates interactive web-based visualizations. Allows users to explore and manipulate the data through zoom, hover, and other interactive features. Ideal for sharing findings or presenting data in a dynamic way. cowplot: Facilitates easy combination of multiple plots into a single layout. Useful for creating composite images with various types of graphs side-by-side or overlaid. Simplifies presenting a multifaceted analysis in a single visual. 5.2 Data Visualization Examples For the purpose of this course, we will discuss examples using base R and ggplot2. 5.2.1 Scatterplot A scatterplot is a graphical representation that reveals the relationship between two continuous variables. By plotting points on a two-dimensional plane, each point corresponds to a pair of values. This visualization is particularly useful for identifying patterns, trends, and potential correlations within the data. Scatterplots are effective when exploring numerical data 5.2.1.1 Base R In base R, we can build scatterplots like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIEJhc2UgUlxucGxvdCh4ID0gY2FycyRkaXNwLFxuICAgICB5ID0gY2FycyRocCxcbiAgICAgY29sID0gXCJzdGVlbGJsdWVcIikifQ== 5.2.1.2 ggplot2 In ggplot2, the syntax for building scatterplots is different, with more options for customization. ggplot2 has different arguments as the second layer for each plot type. For a scatterplot in ggplot2 the second layer to specify is geom_point(). You can create a scatterplot like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFdpdGggZ2dwbG90MlxubGlicmFyeShnZ3Bsb3QyKVxuXG5nZ3Bsb3QoZGF0YSA9IGNhcnMsIGFlcyhcbiAgeCA9IGRpc3AsXG4gIHkgPSBocFxuKSkgK1xuICBnZW9tX3BvaW50KGNvbG9yPVwic3RlZWxibHVlXCIpICtcbiAgdGhlbWVfbWluaW1hbCgpIn0= 5.2.2 Histogram Histograms are used to show the distribution of a variable. Typically they are used for numerical data, histograms present data in intervals or bins along the x-axis, with the frequency or density of observations depicted by the height of the bars on the y-axis. This visualization aids in understanding the central tendency, spread, and shape of the data distribution, providing insights into the data’s overall pattern. 5.2.2.1 Base R eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIEJhc2UgUlxuaGlzdChjYXJzJGhwLFxuICAgICBjb2w9XCJkYXJrZ3JlZW5cIikifQ== 5.2.2.2 With ggplot2 The argument to supply here after creating the first layer is geom_histogram() eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIGdncGxvdDJcbmxpYnJhcnkoZ2dwbG90MilcblxuZ2dwbG90KGRhdGEgPSBjYXJzLCBhZXMoXG4gIHggPSBocFxuKSkgK1xuICBnZW9tX2hpc3RvZ3JhbShjb2xvcj1cImJsYWNrXCIsIGZpbGw9XCJkYXJrZ3JlZW5cIikgK1xuICBsYWJzKFxuICAgIHggPSBcIkhvcnNlcG93ZXIoaHApXCIsXG4gICAgdGl0bGUgPSBcIkhpc3RvZ3JhbSBvZiBIb3JzZXBvd2VyXCJcbiAgKSArXG4gIHRoZW1lX21pbmltYWwoKSJ9 5.2.3 Boxplot Boxplots provide a concise summary of the distribution and key statistics of a dataset. Ideal for numerical data, boxplots display the median, quartiles, and potential outliers in a compact visual format. They are especially valuable for comparing distributions between different groups and identifying variations in central tendency and spread. Boxplots are particularly effective when dealing with large datasets or when a quick overview of data is needed. 5.2.3.1 Base R eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIEJhc2UgUlxuYm94cGxvdChtcGcgfiBjYXJiLCBcbiAgICAgICAgZGF0YSA9IG10Y2FycywgXG4gICAgICAgIGNvbCA9IFwibGlnaHRjb3JhbFwiLCBcbiAgICAgICAgbWFpbiA9IFwiQm94cGxvdCBvZiBtcGcgYnkgQ2FyYnVyZXRvciBUeXBlXCIsIFxuICAgICAgICB4bGFiID0gXCJDYXJidXJldG9yIFR5cGVcIiwgeWxhYiA9IFwiTWlsZXMgcGVyIEdhbGxvblwiKSJ9 5.2.3.2 ggplot2 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIGdncGxvdDJcbmxpYnJhcnkoZ2dwbG90MilcblxuZ2dwbG90KGRhdGEgPSBjYXJzLCBhZXMoXG4gIHggPSBmYWN0b3IoY2FyYiksXG4gIHkgPSBtcGcsXG4gIGZpbGwgPSBmYWN0b3IoY2FyYilcbikpICtcbiAgZ2VvbV9ib3hwbG90KGNvbG9yPVwiYmxhY2tcIiwgZmlsbCA9IFwibGlnaHRjb3JhbFwiKSArXG4gIGxhYnMoXG4gICAgeCA9IFwiQ2FyYnVyZXRvciBUeXBlXCIsXG4gICAgeSA9IFwiTWlsZXMgcGVyIEdhbGxvblwiLFxuICAgIHRpdGxlID0gXCJCb3hwbG90IG9mIG1wZyBieSBDYXJidXJldG9yIFR5cGVcIlxuICApICtcbiAgdGhlbWVfbWluaW1hbCgpIn0= 5.2.4 Barplots Barplots present categorical data with rectangular bars, where the length of each bar corresponds to the frequency or proportion of the category it represents. Barplots are effective for comparing the relative sizes of different categories within a dataset. 5.2.4.1 Base R eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBDcmVhdGUgYSB0YWJsZSBvZiB0aGUgZnJlcXVlbmN5IG9mIGVhY2ggZ2VhciB0eXBlXG5nZWFyX3RhYmxlIDwtIHRhYmxlKGNhcnMkZ2VhcilcblxuIyBXaXRoIEJhc2UgUlxuYmFycGxvdChnZWFyX3RhYmxlLFxuICAgICAgICBjb2wgPSBcImdvbGRcIiwgXG4gICAgICAgIG1haW4gPSBcIkJhcnBsb3Qgb2YgR2VhcnNcIiwgXG4gICAgICAgIHhsYWIgPSBcIkdlYXIgdHlwZVwiLCB5bGFiID0gXCJGcmVxdWVuY3lcIikifQ== 5.2.4.2 ggplot2 In ggplot2, geom_bar and geom_col functions are two commonly used geometries in ggplot2 for creating barplots. Let’s explore the differences and how to build a barplot using the cars dataset. 5.2.4.2.1 geom_bar vs. geom_col geom_bar - geom_bar is used when you want the height of the bar to represent the count of cases in each group. - By default, geom_bar uses stat=“count”, and it counts the number of cases in each group (in this case, the frequency of each gear type). We can build a barplot with geom_bar() like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIGdncGxvdDJcbmxpYnJhcnkoZ2dwbG90MilcblxuIyBVc2luZyBnZW9tX2JhclxuZ2dwbG90KGNhcnMsIGFlcyh4ID0gZmFjdG9yKGdlYXIpKSkgK1xuICBnZW9tX2Jhcihjb2xvciA9IFwiYmxhY2tcIiwgZmlsbCA9IFwiZ29sZFwiKSArXG4gIGxhYnMoXG4gICAgdGl0bGUgPSBcIkJhcnBsb3Qgb2YgR2VhcnNcIixcbiAgICB4ID0gXCJHZWFyIHR5cGVcIixcbiAgICB5ID0gXCJGcmVxdWVuY3lcIlxuICApICtcbiAgdGhlbWVfbWluaW1hbCgpIn0= geom_col - geom_col is used when you want to specify the height of the bars directly, instead of relying on the default count. - You should use geom_col when you have pre-computed heights or when the data is already summarized. We can build a barplot with ggplot2 in R with geom_col() like this. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIGdncGxvdDJcbmxpYnJhcnkoZ2dwbG90MilcblxuIyBVc2luZyBnZW9tX2NvbCB3aXRob3V0IHByZWNvbXB1dGluZ1xuZ2dwbG90KGNhcnMsIGFlcyh4ID0gZmFjdG9yKGdlYXIpKSkgK1xuICBnZW9tX2NvbChmaWxsID0gXCJnb2xkXCIsIGNvbG9yID0gXCJibGFja1wiKSArXG4gIGxhYnMoXG4gICAgdGl0bGUgPSBcIkJhcnBsb3Qgb2YgR2VhcnNcIixcbiAgICB4ID0gXCJHZWFyIHR5cGVcIixcbiAgICB5ID0gXCJGcmVxdWVuY3lcIlxuICApICtcbiAgdGhlbWVfbWluaW1hbCgpIn0= 5.2.5 Pie chart Pie charts are used to display the proportional contribution of each category to a whole. This visualization is particularly effective when presenting parts of a whole and providing a quick overview of the distribution of categorical data. Each slice of the pie represents a category, with its size proportional to the share it contributes to the whole. While widely used, it’s essential to be cautious with pie charts, especially when dealing with a large number of categories, as they can become difficult to interpret accurately. 5.2.5.1 Base R eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBDcmVhdGUgYSB0YWJsZSBvZiB0aGUgZnJlcXVlbmN5IG9mIGVhY2ggY3lsaW5kZXIgdHlwZVxuY3lsX3RhYmxlIDwtIHRhYmxlKGNhcnMkY3lsKVxuXG4jIFdpdGggQmFzZSBSXG5waWUoY3lsX3RhYmxlLCBcbiAgICBtYWluID0gXCJQaWUgQ2hhcnQgb2YgQ2FyIE1vZGVscyBieSBDeWxpbmRlciBUeXBlXCIsXG4gICAgY29sID0gcmFpbmJvdyhsZW5ndGgoY3lsX3RhYmxlKSksXG4gICAgbGFiZWxzID0gcGFzdGUobmFtZXMoY3lsX3RhYmxlKSwgXCI6IFwiLCBjeWxfdGFibGUpLFxuICAgIGNleCA9IDAuOCkifQ== 5.2.5.2 ggplot2 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIGdncGxvdDJcbmxpYnJhcnkoZ2dwbG90MilcblxuIyBDb252ZXJ0IHRoZSB0YWJsZSB0byBhIGRhdGEgZnJhbWVcbmN5bF9kZiA8LSBhcy5kYXRhLmZyYW1lKGN5bF90YWJsZSlcbmNvbG5hbWVzKGN5bF9kZikgPC0gYyhcIkN5bGluZGVyc1wiLCBcIkZyZXF1ZW5jeVwiKVxuXG5cbiMgQ3JlYXRlIGEgYmFyIHBsb3Qgd2l0aCBwb2xhciBjb29yZGluYXRlc1xuZ2dwbG90KGN5bF9kZiwgYWVzKHggPSBcIlwiLCB5ID0gRnJlcXVlbmN5LCBmaWxsID0gZmFjdG9yKEN5bGluZGVycykpKSArXG4gIGdlb21fYmFyKHN0YXQgPSBcImlkZW50aXR5XCIsIHdpZHRoID0gMSwgY29sb3IgPSBcIndoaXRlXCIpICtcbiAgY29vcmRfcG9sYXIodGhldGEgPSBcInlcIikgK1xuICB0aGVtZV92b2lkKCkgK1xuICBsYWJzKFxuICAgIHRpdGxlID0gXCJQaWUgQ2hhcnQgb2YgQ2FyIE1vZGVscyBieSBDeWxpbmRlciBUeXBlXCIpICtcbiAgc2NhbGVfZmlsbF9kaXNjcmV0ZShuYW1lID0gXCJOdW1iZXIgb2YgQ3lsaW5kZXJzXCIpIn0= There is a slight syntax difference for bar charts in ggplot2. Read more about it here 5.2.6 Dotplots Dotplots are a straightforward method to visualize the distribution of a dataset, particularly useful for smaller datasets. Individual dots are placed along a number line, with each dot representing an observation. Dotplots provide a clear representation of the data points and help identify patterns and clusters. While not as common as some other types of visualizations, dotplots can be valuable when a simple, uncluttered display of data is desired, facilitating a direct and intuitive interpretation. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBDb3VudCB0aGUgZnJlcXVlbmN5IG9mIGVhY2ggY3lsaW5kZXIgdHlwZVxuY3lsX2NvdW50cyA8LSB0YWJsZShjYXJzJGN5bClcblxuIyBXaXRoIEJhc2UgUlxucGxvdChjeWxfY291bnRzLCB0eXBlID0gXCJoXCIsIFxuICAgICBsd2QgPSAxMCwgY29sID0gXCJsaWdodGJsdWVcIiwgXG4gICAgIHhheHQgPSBcIm5cIiwgbWFpbiA9IFwiRG90IFBsb3Qgb2YgQ2FyIE1vZGVscyBieSBDeWxpbmRlciBUeXBlXCIsIFxuICAgICB4bGFiID0gXCJOdW1iZXIgb2YgQ3lsaW5kZXJzXCIsIHlsYWIgPSBcIkNvdW50XCIpXG5heGlzKDEsIGF0ID0gc2VxX2Fsb25nKGN5bF9jb3VudHMpLCBsYWJlbHMgPSBuYW1lcyhjeWxfY291bnRzKSkifQ== eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgbXRjYXJzXG5jYXJzIDwtIGRhdGFzZXRzOjptdGNhcnNcblxuIyBXaXRoIGdncGxvdDJcbmxpYnJhcnkoZ2dwbG90MilcblxuIyBDcmVhdGUgYSBkb3QgcGxvdFxuZ2dwbG90KGNhcnMsIGFlcyh4ID0gZmFjdG9yKGN5bCkpKSArXG4gIGdlb21fZG90cGxvdChmaWxsID0gXCJsaWdodGJsdWVcIikgK1xuICBsYWJzKFxuICAgIHRpdGxlID0gXCJEb3QgUGxvdCBvZiBDYXIgTW9kZWxzIGJ5IEN5bGluZGVyIFR5cGVcIixcbiAgICB4ID0gXCJOdW1iZXIgb2YgQ3lsaW5kZXJzXCIsXG4gICAgeSA9IFwiQ291bnRcIlxuICApIn0= 5.3 WHICH VISUALIZATION PACKAGE TO USE? Relevance: Base R for quick checks, ggplot2 for extensive customization, lattice for multi-panel plots, plotly for interactivity, cowplot for combined visuals. Audience: Base R graphics might suffice for technical reports, while ggplot2 or plotly cater to broader audiences who benefit from visual clarity and interactivity. Learning curve: Start with simpler packages like base R if new to R, then graduate to ggplot2 or others for advanced visualizations. 5.4 CODE CHALLENGE You are to use base R and ggplot2 for each question below. For the next 5 questions, using the CO2 dataset from the datasets package: 1. Visualize the distribution of concentration levels and assign the base R visualization to base_viz1 and ggplot one to gg_plot1 Visualize the distribution of uptake by type using a boxplot and assign the base R visualization to base_boxplot and ggplot one to gg_boxplot For each plant, visualize the concentration levels using a barplot. Assign the base R viz to base_bar and ggplot to gg_bar respectively Create a scatterplot to show the relationship between concentration and uptake levels and assign the base R and ggplot scatterplots to base_scatterplot and gg_scatterplot respectively Visualize the distribution of sepal length in base R and petal width with ggplot2 using the iris dataset and assign the base R visualization to base_viz2 and ggplot one to gg_plot2 Visualize the distribution of petal lengths by species using a boxplot using the iris dataset and assign the base R visualization to base_iris_boxplot and ggplot one to gg_iris_boxplot Visualize the distribution of car weights by the number of cylinders using the mtcars dataset and assign the base R visualization to base_viz3 and ggplot one to gg_plot3 Create a scatterplot to show the relationship between car weight and miles per gallon and assign the base R and ggplot scatterplots to base_car_scatterplot and gg_car_scatterplot respectively Using the airquality dataset, visualize the wind speed for each day using a barplot. Assign the base R viz to base_wind_bar and ggplot to gg_wind_bar respectively Visualize the distribution of sepal widths by species using the iris dataset and assign the base R visualization to base_iris_viz and ggplot one to gg_iris_plot In your pull request, add the plot images and the script used to create these plots. Use the ggsave function to save your plots. This material will help you. "],["functions.html", "Chapter 6 FUNCTIONS 6.1 CREATING A FUNCTION 6.2 Examples of functions 6.3 FUNCTIONS WITH DEFAULT PARAMETERS 6.4 CODE CHALLENGE", " Chapter 6 FUNCTIONS In R, functions are reusable blocks of code that perform specific tasks. They are essential for organizing, streamlining and making your code more readable and maintainable. Functions in R typically take in input parameters, perform operations based on those inputs and return a result. 6.1 CREATING A FUNCTION Let us see the basic structure of a function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEJhc2ljIHN0cnVjdHVyZSBvZiBhIGZ1bmN0aW9uXG5mdW5jdGlvbl9uYW1lIDwtIGZ1bmN0aW9uKHBhcmFtZXRlcjEsIHBhcmFtZXRlcjIsIC4uLikge1xuICAjIEZ1bmN0aW9uIGJvZHkgLSBjb2RlIHRvIHBlcmZvcm0gdGhlIHRhc2tcbiAgIyAuLi5cbiAgXG4gICMgUmV0dXJuIHN0YXRlbWVudCAob3B0aW9uYWwpIC0gc3BlY2lmaWVzIHRoZSB2YWx1ZSB0byBiZSByZXR1cm5lZFxuICAjIHJldHVybihzb21lX3ZhbHVlKVxufVxuXG4jIENhbGwgYSBmdW5jdGlvblxucmVzdWx0IDwtIGZ1bmN0aW9uX25hbWUocGFyYW1ldGVyKSJ9 6.1.1 Overview of a basic function structure Here is an overview of the basic structure of a function: - function_name: This is the name you give to your function. - parameters: These are variables that represent the input values passed to the function. You can have zero or more parameters. - Function body: This is the block of code inside the function that performs the desired operations. - Return statement: (optional) This statement specifies the value that the function will return. If no return statement is provided, the function returns the result of the last evaluated expression. To call a function, we will just need to type the function name, that is, the variable the function was assigned to and then add a bracket and add a parameter or parameters where applicable. 6.2 Examples of functions Creating a function that calculates the area of a rectangle. Whenever creating a function, it is important to break down what you want your function to do. We want to create a function that can calculate the area of a rectangle. From basic mathematics, the area of a rectangle can be calculated from this: Area = length * width Let us create a function to calculate the area of a rectangle programmatically in R. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZ1bmN0aW9uIHRvIGNhbGN1bGF0ZSBhcmVhIG9mIGEgcmVjdGFuZ2xlXG5jYWxjdWxhdGVfYXJlYSA8LSBmdW5jdGlvbihsZW5ndGgsIHdpZHRoKSB7XG4gICMgTXVsdGlwbHkgbGVuZ3RoIGJ5IHdpZHRoIGFuZCBhc3NpZ24gdG8gdmFyaWFibGUgY2FsbGVkIGFyZWFcbiAgYXJlYSA8LSBsZW5ndGggKiB3aWR0aFxufVxuXG4jIENhbGwgZnVuY3Rpb25cbnJlY3RhbmdsZSA8LSBjYWxjdWxhdGVfYXJlYSg1LDE1KVxuXG4jIFByaW50IHJlY3RhbmdsZVxucmVjdGFuZ2xlIn0= This works. But when creating complex functions, due to expected behavior, it is always recommended to use return explicitly to return a value. Given this, let us properly define our calculate_area function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZ1bmN0aW9uIHRvIGNhbGN1bGF0ZSBhcmVhIG9mIGEgcmVjdGFuZ2xlXG5jYWxjdWxhdGVfYXJlYSA8LSBmdW5jdGlvbihsZW5ndGgsIHdpZHRoKSB7XG4gICMgTXVsdGlwbHkgbGVuZ3RoIGJ5IHdpZHRoIGFuZCBhc3NpZ24gdG8gdmFyaWFibGUgY2FsbGVkIGFyZWFcbiAgYXJlYSA8LSBsZW5ndGggKiB3aWR0aFxuICBcbiAgIyBFeHBsaWNpdGx5IHJldHVybiBhcmVhXG4gIHJldHVybihhcmVhKVxufVxuXG4jIENhbGwgZnVuY3Rpb25cbnJlY3RhbmdsZSA8LSBjYWxjdWxhdGVfYXJlYSg1LDE1KVxuXG4jIFByaW50IHJlY3RhbmdsZVxucmVjdGFuZ2xlIn0= Now we have defined our function properly to return a value. Creating a basic function to add two numbers We will create a function that takes two numbers and returns the sum. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZ1bmN0aW9uIHRvIGFkZCB0d28gbnVtYmVyc1xuYWRkX251bWJlcnMgPC0gZnVuY3Rpb24oeCwgeSkge1xuICByZXN1bHQgPC0geCArIHlcbiAgXG4gICMgUmV0dXJuIHJlc3VsdFxuICByZXR1cm4ocmVzdWx0KVxufVxuXG4jIENhbGwgZnVuY3Rpb24gYW5kIGFzc2lnbiByZXN1bHQgdG8gYSB2YXJpYWJsZVxuc3VtX3Jlc3VsdCA8LSBhZGRfbnVtYmVycygzLCA1KVxuXG4jIFByaW50IHJlc3VsdFxuc3VtX3Jlc3VsdCJ9 6.3 FUNCTIONS WITH DEFAULT PARAMETERS Sometimes, some functions can take on default parameters and can still run without throwing up an error. Let us revisit our calculate area function again and let us call it without adding any parameters. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZ1bmN0aW9uIHRvIGNhbGN1bGF0ZSBhcmVhIG9mIGEgcmVjdGFuZ2xlXG4jY2FsY3VsYXRlX2FyZWEgPC0gZnVuY3Rpb24obGVuZ3RoLCB3aWR0aCkge1xuIyAgIyBNdWx0aXBseSBsZW5ndGggYnkgd2lkdGggYW5kIGFzc2lnbiB0byB2YXJpYWJsZSBjYWxsZWQgYXJlYVxuIyAgYXJlYSA8LSBsZW5ndGggKiB3aWR0aFxuIyAgXG4gICMgRXhwbGljaXRseSByZXR1cm4gYXJlYVxuIyAgcmV0dXJuKGFyZWEpXG4jfVxuXG4jIENhbGwgZnVuY3Rpb25cbiNjYWxjdWxhdGVfYXJlYSgpIn0= Error! We get the error: “Error in calculate_area() : argument”length” is missing, with no default” This is because we did not add default parameters to our function. This is a form of error-handling. For now let us add default parameters to our function which will ensure our function runs even when no values are supplied. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZ1bmN0aW9uIHdpdGggZGVmYXVsdCB2YWx1ZXMgZm9yIHBhcmFtZXRlcnNcbmNhbGN1bGF0ZV9hcmVhX3dpdGhfZGVmYXVsdHMgPC0gZnVuY3Rpb24obGVuZ3RoID0gMSwgd2lkdGggPSAxKSB7XG4gIGFyZWEgPC0gbGVuZ3RoICogd2lkdGhcbiAgcmV0dXJuKGFyZWEpXG59XG5cbiMgQ2FsbCBmdW5jdGlvbiB3aXRob3V0IHNwZWNpZnlpbmcgYXJndW1lbnRzXG5jYWxjdWxhdGVfYXJlYV93aXRoX2RlZmF1bHRzKCkifQ== Our function now returns 1 and does not return an error! Defining functions with a default parameter or parameters ensure our function do not return errors when run without parameters. There are other aspects of functions you should pay attention to when creating functions. You need to ensure you implement some error-handling features to handle some unexpected behaviors in your function. For example in our calculate_area() function, we can add an error-handling feature that ensures the parameters cannot be zero since multiplying any number by zero returns zero. Let us implement an error handling feature that makes sure we do not have any zero or negative parameters. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEVycm9yIGhhbmRsaW5nIGV4YW1wbGVcbiNjYWxjdWxhdGVfYXJlYV9zYWZlIDwtIGZ1bmN0aW9uKGxlbmd0aCwgd2lkdGgpIHtcbiMgIGlmIChsZW5ndGggPD0gMCB8fCB3aWR0aCA8PSAwKSB7XG4jICAgIHN0b3AoXCJMZW5ndGggYW5kIHdpZHRoIG11c3QgYmUgcG9zaXRpdmUgdmFsdWVzLlwiKVxuIyAgfVxuIyAgYXJlYSA8LSBsZW5ndGggKiB3aWR0aFxuIyAgcmV0dXJuKGFyZWEpXG4jfVxuI1xuIyBDYWxsIGZ1bmN0aW9uIHdpdGggZXJyb3JcbiNlcnJvcl9yZWN0YW5nbGUxIDwtIGNhbGN1bGF0ZV9hcmVhX3NhZmUoLTIsIDgpXG4jZXJyb3JfcmVjdGFuZ2xlMiA8LSBjYWxjdWxhdGVfYXJlYV9zYWZlKDUsIDApXG5cbiMgUHJpbnQgcmVzdWx0XG4jZXJyb3JfcmVjdGFuZ2xlXG4jZXJyb3JfcmVjdGFuZ2xlMiJ9 Good. Supplying a negative number and also 0 returns errors. We can make sure we handle unexpected behavior with our function. 6.4 CODE CHALLENGE Create a function called check_even_odd that takes in a given positive integer and checks if it is an even or odd number. Create a function named is_prime that checks if a given positive integer is a prime number. The function should return a logical value (TRUE or FALSE) Given a triangle with a base and a height, create a function called calculate_triangle_area that calculates the area of said triangle Create a function called find_maximum that takes in two numbers as arguments and returns the larger of the two. Create a function named calculate_average that takes a numeric vector as an argument and returns the average (mean) of the values. Develop a function named is_palindrome that checks if a given string is a palindrome. A palindrome is a word, phrase, or sequence of characters that reads the same forward and backward, ignoring spaces, punctuation, and capitalization. Use tolower() to convert any input to lower cases inside your function code before you do anything else. Create a function named calculate_factorial that takes a positive integer as an argument and returns the factorial of that number. The factorial of a non-negative integer n is the product of all positive integers less than or equal to n. Read more about factorial here Create a function called is_positive that takes a numeric value as an argument and returns TRUE if the number is positive, and FALSE otherwise. Implement a function named is_leap_year that takes a year (as a positive integer) as an argument and returns TRUE if it’s a leap year and FALSE otherwise. A leap year is divisible by 4, but not divisible by 100 unless it is also divisible by 400. Create a function named reverse_vector that takes a vector as an argument and returns a new vector with the elements reversed. The function should not modify the original vector, only reverse the order of elements. "],["group-manipulation.html", "Chapter 7 GROUP MANIPULATION 7.1 APPLY FAMILY 7.2 aggregate() 7.3 plyr 7.4 RESHAPING 7.5 CODE CHALLENGE", " Chapter 7 GROUP MANIPULATION Group manipulation in R refers to operations or transformations applied to data grouped by one or more variables. 7.1 APPLY FAMILY The apply family in R comprises a set of powerful and versatile functions designed for operations on matrices, arrays, lists, and vectors. These functions, including apply(), lapply(), sapply(), vapply(), and mapply(), allow us to apply a specified function to the rows or columns of a matrix, elements of a list or vector, or multiple vectors simultaneously. These functions are commonly used in tasks such as calculating summary statistics, performing transformations, or building models within specific groups of data. 7.1.1 The Apply Functions Understanding the Family: - apply(): The most general function, allowing you to specify the margins (rows, columns, etc.) over which to apply a function. - lapply(): Applies a function to each element of a list, returning a new list with the transformed elements. - sapply: Similar to lapply, but simplifies the return value to a vector or matrix. - vapply(): Like sapply, but applies a function by variable instead of element, useful for data frames. - tapply(): Specifically designed for group manipulation, applies a function to each group defined by a factor variable. 7.1.2 apply() The apply() function is a powerful tool for applying a function repeatedly to elements of an array or matrix, often eliminating the need for explicit loops. It offers flexibility and control over how the function is applied, making it a extremely efficient in data manipulation. SYNTAX: apply(X, MARGIN, FUN, ...) X: The array or matrix on which the function will be applied. MARGIN: Specifies the margin or dimension along which the function is applied (1 for rows, 2 for columns). FUN: The function to be applied. …: Additional arguments to be passed to the function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFN1bSB0aGUgZWxlbWVudHMgb2YgZWFjaCBjb2x1bW4gaW4gYSBtYXRyaXhcbm1hdHJpeF9kYXRhIDwtIG1hdHJpeCgxOjYsIG5yb3cgPSAyKVxuXG4jIEFwcGx5IHN1bSBmdW5jdGlvbiB0byBtYXRyaXhfZGF0YVxuY29sdW1uX3N1bXMgPC0gYXBwbHkobWF0cml4X2RhdGEsIDIsIHN1bSlcblxuY29sdW1uX3N1bXMifQ== Let us take another look at an example where we use apply() to multiply the elements of each row of a matrix eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIERlZmluZSBhIG1hdHJpeFxubWF0cml4X2RhdGEgPC0gbWF0cml4KDE6NiwgbnJvdyA9IDIpXG5cbiMgQXBwbHkgbXVsdGlwbGljYXRpb24gZnVuY3Rpb24gdG8gbWF0cml4X2RhdGEgYWxvbmcgcm93c1xucm93X3Byb2R1Y3RzIDwtIGFwcGx5KG1hdHJpeF9kYXRhLCAxLCBwcm9kKVxuXG5yb3dfcHJvZHVjdHMifQ== Can you try to use apply() to calculate the mean of each column in a matrix? The matrix is already predefined below eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG1hdHJpeFxuXG5cbiMgQ2FsY3VsYXRlIHRoZSBtZWFuIG9mIGVhY2ggY29sdW1uIiwic29sdXRpb24iOiIjIENyZWF0ZSBhIG1hdHJpeFxubWF0cml4X2RhdGEgPC0gbWF0cml4KDE6NiwgbnJvdyA9IDIpXG5cbiMgQ2FsY3VsYXRlIHRoZSBtZWFuIG9mIGVhY2ggY29sdW1uXG5jb2xfbWVhbnMgPC0gYXBwbHkobWF0cml4X2RhdGEsIDIsIG1lYW4pXG5jb2xfbWVhbnMifQ== 7.1.3 lapply() lapply stands for “list apply” and is used to apply a function to each element of a list. It returns a list where each element is the result of applying the specified function to the corresponding element of the input list. SYNTAX: lapply(X, FUN, ...) eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG5hbWVkIGxpc3Rcbm51bV9saXN0IDwtIGxpc3QoYSA9IDEsIGIgPSAyLCBjID0gMylcblxuIyBTcXVhcmUgZWFjaCBlbGVtZW50IG9mIGEgbGlzdFxuc3F1YXJlZF9saXN0IDwtIGxhcHBseShudW1fbGlzdCwgZnVuY3Rpb24oeCkgeF4yKVxuXG4jIFByaW50IHJlc3VsdFxuc3F1YXJlZF9saXN0In0= We can also use lapply() on character type lists. Let us consider an example below where we convert each list element from lower to uppercase. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGNoYXJhY3RlciBsaXN0XG5jaGFyX2xpc3QgPC0gbGlzdChuYW1lMSA9IFwiam9oblwiLCBuYW1lMiA9IFwiamFuZVwiLCBuYW1lMyA9IFwiYm9iXCIpXG5cbiMgQ29udmVydCBlYWNoIGNoYXJhY3RlciBlbGVtZW50IHRvIHVwcGVyY2FzZVxudXBwZXJjYXNlX2xpc3QgPC0gbGFwcGx5KGNoYXJfbGlzdCwgZnVuY3Rpb24oeCkgdG91cHBlcih4KSlcblxudXBwZXJjYXNlX2xpc3QifQ== You might come across various use cases where you will find lapply() very handy. 7.1.4 sapply() Similar to lapply, sapply stands for “simplified apply.” It applies a function to each element of a list but attempts to simplify the result into a vector or matrix if possible. SYNTAX: sapply(X, FUN, ...) eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFNxdWFyZSBlYWNoIGVsZW1lbnQgb2YgYSBsaXN0IGFuZCBzaW1wbGlmeSB0aGUgcmVzdWx0XG5udW1fbGlzdCA8LSBsaXN0KGEgPSAxLCBiID0gMiwgYyA9IDMpXG5zcXVhcmVkX3ZlY3RvciA8LSBzYXBwbHkobnVtX2xpc3QsIGZ1bmN0aW9uKHgpIHheMilcblxuIyBQcmludCByZXN1bHRcbnNxdWFyZWRfdmVjdG9yIn0= We could also decide to use sapply() to double the elements in a numeric list for example. We can do that like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIG51bWVyaWMgbGlzdFxubnVtX2xpc3QgPC0gbGlzdChhID0gNCwgYiA9IDUsIGMgPSA2KVxuXG4jIERvdWJsZSBlYWNoIGVsZW1lbnQgb2YgdGhlIGxpc3QgYW5kIHNpbXBsaWZ5IHRoZSByZXN1bHRcbmRvdWJsZWQgPC0gc2FwcGx5KG51bV9saXN0LCBmdW5jdGlvbih4KSB4ICogMilcblxuIyBQcmludCByZXN1bHRcbmRvdWJsZWQifQ== As you can see, sapply() simplifies our output into a vector again. In case you want to remember what it does, it is used to perform operations on lists and tries to return a vector if it is possible. sapply() can also be used for lists containing wholly string data types. Let us say we had a list of names. We can use sapply() to concatenate “Hello,” before each name. How can we do that? Easy. We can use sapply() to apply base R’s paste() function to do the job for us like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGNoYXJhY3RlciBsaXN0XG5jaGFyX2xpc3QgPC0gbGlzdChuYW1lMSA9IFwiRmF0aW1hXCIsIG5hbWUyID0gXCJCb2JcIiwgbmFtZTMgPSBcIlN0ZXZlXCIpXG5cbiMgQ29uY2F0ZW5hdGUgXCJIZWxsbywgXCIgdG8gZWFjaCBjaGFyYWN0ZXIgZWxlbWVudCBhbmQgc2ltcGxpZnkgdGhlIHJlc3VsdFxuZ3JlZXRpbmcgPC0gc2FwcGx5KGNoYXJfbGlzdCwgZnVuY3Rpb24oeCkgcGFzdGUoXCJIZWxsbywgXCIsIHgpKVxuXG5ncmVldGluZyJ9 7.1.5 vapply() vapply is similar to sapply but allows you to specify the type and shape of the result, providing a safer and more predictable output. SYNTAX: vapply(X, FUN, FUN.VALUE, ...) eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFNxdWFyZSBlYWNoIGVsZW1lbnQgb2YgYSB2ZWN0b3IgYW5kIHNwZWNpZnkgdGhlIHJlc3VsdCB0eXBlXG5udW1fdmVjdG9yIDwtIGMoMSwgMiwgMylcbnNxdWFyZWRfdmVjdG9yIDwtIHZhcHBseShudW1fdmVjdG9yLCBmdW5jdGlvbih4KSB4XjIsIG51bWVyaWMoMSkpXG5cbiMgUHJpbnQgcmVzdWx0XG5zcXVhcmVkX3ZlY3RvciJ9 7.1.6 tapply() tapply() is specifically designed for group-wise operations. It applies a function to subsets of a vector defined by a factor variable SYNTAX: tapply(X, INDEX, FUN, ...) eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENhbGN1bGF0ZSB0aGUgbWVhbiBvZiBhIG51bWVyaWMgdmVjdG9yIGZvciBlYWNoIGdyb3VwIGRlZmluZWQgYnkgYSBmYWN0b3JcbnZhbHVlcyA8LSBjKDEwLCAyMywgMTMsIDg0LCA1MClcbmdyb3VwcyA8LSBmYWN0b3IoYyhcIkFcIiwgXCJCXCIsIFwiQVwiLCBcIkJcIiwgXCJBXCIpKVxuXG4jIENhbGN1bGF0ZSB0aGUgbWVhblxubWVhbl9ieV9ncm91cCA8LSB0YXBwbHkodmFsdWVzLCBncm91cHMsIG1lYW4pXG5cbiMgUHJpbnQgcmVzdWx0XG5tZWFuX2J5X2dyb3VwIn0= 7.2 aggregate() In R, the aggregate function is another powerful tool for manipulating data, specifically focused on calculating summary statistics for subsets of a data frame based on grouping variables. Think of it as a specialized tool for calculating group means, medians, counts, etc. The aggregate function can help replace cumbersome loops and manual calculations for grouped statistics, it is very flexible and allows a user more control over specific variables or grouping factors. SYNTAX: aggregate(x, by, FUN, ...) 7.2.1 Arguments Arguments: - x: The variable(s) for which you want to calculate the summary statistics. - by: A list of columns containing the grouping variables. - FUN: The function to apply to each group. Built-in options like mean, median, sum, etc., or your own custom function. - …: Additional arguments passed to the FUN function. Let us see the aggregate() function in action. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgY2hpY2t3dHMgZGF0YVxuY2hpY2t3ZWlnaHQgPC0gZGF0YXNldHM6OmNoaWNrd3RzXG5cbnN1bW1hcnlfc3RhdHMgPC0gYWdncmVnYXRlKHdlaWdodCB+IGZlZWQsIGRhdGEgPSBjaGlja3dlaWdodCwgbWVhbilcblxuIyBQcmludCBvdXQgcmVzdWx0XG5zdW1tYXJ5X3N0YXRzIn0= aggregate() is flexible and can be used to calculate multiple statistics by providing a vector of functions for the FUN argument. aggregate() might be a complex for new R users to fully grasp and it is usually recommended for new users to use dplyr’s group_by and summarize() functions due to its more readable syntax. 7.3 plyr plyr is an R package that provides a set of tools for splitting, applying, and combining data in a systematic way. This pattern is common in data analysis: you break down a complex problem into smaller pieces, manipulate each piece, and then combine the results back together. The plyr package introduces a family of functions that follow a common pattern for data manipulation. The key functions in the plyr package include: ddply: This function is used for splitting a data frame, applying a function to each subset, and then combining the results into a data frame. It’s particularly useful for tasks involving grouping and summarizing data. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJsaWJyYXJ5KHBseXIpXG5cbiMgU3ludGF4XG4jZGRwbHkoZGF0YV9mcmFtZSxcbiMgICAgICAuKGdyb3VwaW5nX3ZhcmlhYmxlKSwgXG4jICAgICAgc3VtbWFyaXNlLCBcbiMgICAgICBtZWFuX3ZhbHVlID0gbWVhbihudW1lcmljX3ZhcmlhYmxlKSlcblxuIyBMb2FkIHRoZSBtdGNhcnMgZGF0YXNldFxuZGF0YShtdGNhcnMpXG5cbiMgVXNlIGRkcGx5IHRvIGNhbGN1bGF0ZSB0aGUgbWVhbiBhbmQgc3VtIG9mIG1wZyBieSB0aGUgbnVtYmVyIG9mIGN5bGluZGVyc1xuZGRwbHkobXRjYXJzLCAuKGN5bCksIHN1bW1hcmlzZSwgbWVhbl9tcGcgPSBtZWFuKG1wZyksIHN1bV9tcGcgPSBzdW0obXBnKSkifQ== ldply(): It is used for applying a function to each element of a list and then combining the results into a data frame. This is handy when working with lists of data. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgcGx5clxubGlicmFyeShwbHlyKVxuXG4jIFN5bnRheCBvZiBsZHBseSgpXG4jbGRwbHkobGlzdF9vZl9kYXRhX2ZyYW1lcywgXG4jICAgICAgZnVuY3Rpb24oeCkgc3VtbWFyaXNlKHgsIG1lYW5fdmFsdWUgPSBtZWFuKG51bWVyaWNfdmFyaWFibGUpKSlcblxuXG4jIENyZWF0ZSBhIGxpc3Qgb2YgZGF0YSBmcmFtZXMgKHlvdSBjYW4gcmVwbGFjZSB0aGlzIHdpdGggeW91ciBvd24gbGlzdClcbmxpc3Rfb2ZfZGF0YV9mcmFtZXMgPC0gbGlzdChcbiAgZGF0YS5mcmFtZShpZCA9IDE6MywgdmFsdWUgPSBjKDEwLCAxNSwgMjApKSxcbiAgZGF0YS5mcmFtZShpZCA9IDQ6NiwgdmFsdWUgPSBjKDI1LCAzMCwgMzUpKVxuKVxuXG4jIEFwcGx5IGxkcGx5XG5sZHBseShsaXN0X29mX2RhdGFfZnJhbWVzLCBmdW5jdGlvbih4KSBzdW1tYXJpc2UoeCwgbWVhbl92YWx1ZSA9IG1lYW4odmFsdWUpKSkifQ== adply(): Similar to ddply, but it returns an array or matrix as the result. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFN5bnRheCBvZiBhZHBseSgpXG4jYWRwbHkoZGF0YV9mcmFtZSwgXG4jICAgICAgLihncm91cGluZ192YXJpYWJsZSksIFxuIyAgICAgIGZ1bmN0aW9uKHgpIGMobWVhbl92YWx1ZSA9IG1lYW4oeCRudW1lcmljX3ZhcmlhYmxlKSkpIn0= 7.3.1 Other Key plyr functions plyr: The core function for “split-apply-combine” operations. mutate: Add or modify columns within each data subset. rename: Rename columns after applying functions. arrange: Reorder rows based on specified columns. summarize: Create a new data frame with summary statistics for each group. join: Combine data subsets based on shared variables. It would be interesting to note that, dplyr, is now preferred over plyr due to its more readable syntax and modern approaches to statistical computing. 7.4 RESHAPING In R, reshaping refers to the process of restructuring or transforming the layout of your data, often changing it from one form to another. This is particularly useful when working with data in different formats, and it’s a common step in data preparation and analysis. Reshaping is typically done using functions that rearrange the rows and columns of your data to make it more suitable for your analysis or visualization needs. There are two primary types of reshaping in R and they are: - wide to long reshaping - long to wide reshaping 7.4.1 Wide to Long Wide to long reshaping transforms a dataset from a wide-format dataset, where each variable has its own column, into a long-format dataset, where all the variable values are stacked in a single column with an additional column indicating the variable name. We can use two functions to achieve this: - pivot_longer() from the tidyr package - gather() from the dplyr package. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIHRpZHlyOjpwaXZvdF9sb25nZXJcbmxpYnJhcnkodGlkeXIpXG4jIFN5bnRheFxuI2xvbmdfZGF0YSA8LSBwaXZvdF9sb25nZXIod2lkZV9kYXRhLCBjb2xzID0gc3RhcnRzX3dpdGgoXCJ2YXJpYWJsZV9wcmVmaXhcIiksXG4jbmFtZXNfdG8gPSBcInZhcmlhYmxlX25hbWVcIiwgdmFsdWVzX3RvID0gXCJ2YWx1ZVwiKVxuXG4jIExvYXJkIGlyaXMgZGF0YXNldFxuaXJpcyA8LSBkYXRhc2V0czo6aXJpc1xuXG4jIFdpZGUgdG8gTG9uZyBSZXNoYXBpbmcgdXNpbmcgdGlkeXI6OnBpdm90X2xvbmdlclxubG9uZ19pcmlzIDwtIHBpdm90X2xvbmdlcihpcmlzLCBjb2xzID0gLVNwZWNpZXMsIG5hbWVzX3RvID0gXCJWYXJpYWJsZVwiLFxuICAgICAgICAgICAgICAgICAgICAgICAgICB2YWx1ZXNfdG8gPSBcIlZhbHVlXCIpXG5cbiMgUHJldmlldyB0cmFuc2Zvcm1lZCBkYXRhZnJhbWVcbmhlYWQobG9uZ19pcmlzKSJ9 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIGRwbHlyOjpnYXRoZXJcbmxpYnJhcnkoZHBseXIpXG5cblxuI2xvbmdfZGF0YSA8LSBnYXRoZXIod2lkZV9kYXRhLFxuIyAgICAgICAgICAgICAgICAgICAga2V5ID0gXCJ2YXJpYWJsZV9uYW1lXCIsIFxuIyAgICAgICAgICAgICAgICAgICAgdmFsdWUgPSBcInZhbHVlXCIsIFxuIyAgICAgICAgICAgICAgICAgICAgc3RhcnRzX3dpdGgoXCJ2YXJpYWJsZV9wcmVmaXhcIikpXG5cbiMgQ3JlYXRlIGEgc2ltcGxlIHdpZGUtZm9ybWF0IGRhdGFzZXRcbndpZGVfZGF0YSA8LSBkYXRhLmZyYW1lKFxuICBJRCA9IDE6NSxcbiAgdmFyX0EgPSBjKDEwLCAyMCwgMzAsIDQwLCA1MCksXG4gIHZhcl9CID0gYygxNSwgMjUsIDM1LCA0NSwgNTUpLFxuICB2YXJfQyA9IGMoMjIsIDMyLCA0MiwgNTIsIDYyKVxuKVxuXG4jIFZpZXcgdGhlIG9yaWdpbmFsIHdpZGUtZm9ybWF0IGRhdGFzZXRcbndpZGVfZGF0YVxuXG4jIFdpZGUgdG8gTG9uZyBSZXNoYXBpbmcgdXNpbmcgZHBseXI6OmdhdGhlclxubG9uZ19kYXRhIDwtIGdhdGhlcih3aWRlX2RhdGEsIGtleSA9IFwidmFyaWFibGVfbmFtZVwiLCB2YWx1ZSA9IFwidmFsdWVcIiwgLUlEKVxuXG4jIFZpZXcgdGhlIHJlc2hhcGVkIGxvbmctZm9ybWF0IGRhdGFzZXRcbmxvbmdfZGF0YSJ9 7.4.2 Long to Wide Transforms a long-format dataset into a wide-format dataset, where each unique value in a specified column becomes a new column. We can use: - pivot_wider from tidyr - spread from dplyr eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIHRpZHlyOjpwaXZvdF93aWRlclxubGlicmFyeSh0aWR5cilcblxuIyBQaXZvdCB3aWRlciBcbiMgd2lkZV9kYXRhIDwtIHBpdm90X3dpZGVyKGxvbmdfZGF0YSwgbmFtZXNfZnJvbSA9IFwidmFyaWFibGVfbmFtZVwiLFxuI3ZhbHVlc19mcm9tID0gXCJ2YWx1ZVwiKVxuXG4jIExvYWQgbXRjYXJzXG5tdGNhcnMgPC0gZGF0YXNldHM6Om10Y2Fyc1xuXG4jIExvbmcgdG8gV2lkZSBSZXNoYXBpbmcgdXNpbmcgdGlkeXI6OnBpdm90X3dpZGVyXG53aWRlX2RhdGFfdGlkeXIgPC0gcGl2b3Rfd2lkZXIobXRjYXJzLCBuYW1lc19mcm9tID0gXCJnZWFyXCIsXG4gICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgdmFsdWVzX2Zyb20gPSBcIm1wZ1wiKVxuXG4jIFZpZXcgdGhlIHJlc2hhcGVkIHdpZGUtZm9ybWF0IGRhdGFzZXRcbndpZGVfZGF0YV90aWR5ciJ9 For the spread() function from the dplyr package. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFVzaW5nIGRwbHlyOjpzcHJlYWRcbmxpYnJhcnkoZHBseXIpXG5cbiMgUGl2b3QgZnJvbSBsb25nIHRvIHdpZGVcbiN3aWRlX2RhdGEgPC0gc3ByZWFkKGxvbmdfZGF0YSwga2V5ID0gXCJ2YXJpYWJsZV9uYW1lXCIsIHZhbHVlID0gXCJ2YWx1ZVwiKVxuXG4jIExvYWQgbXRjYXJzXG5tdGNhcnMgPC0gZGF0YXNldHM6Om10Y2Fyc1xuXG4jIExvbmcgdG8gV2lkZSBSZXNoYXBpbmcgdXNpbmcgZHBseXI6OnNwcmVhZFxud2lkZV9kYXRhX2RwbHlyIDwtIHNwcmVhZChtdGNhcnMsIGtleSA9IFwiZ2VhclwiLCB2YWx1ZSA9IFwibXBnXCIpXG5cbiMgVmlldyB0aGUgcmVzaGFwZWQgd2lkZS1mb3JtYXQgZGF0YXNldFxud2lkZV9kYXRhX2RwbHlyIn0= 7.5 CODE CHALLENGE Create a list named fruits containing the elements: apple, mango, peach, orange, watermelon, avocado, and pawpaw. Use lapply() to apply an anonymous function that counts the number of characters in each element. Assign the resulting list to a variable named fruits_char_counts Using the chickwts dataset, calculate the average weight for each feed category using the tapply() function. Assign the resulting averages to a variable named feed_avg_weights Reshape the airquality dataset from wide to long format. Assign the resulting long format dataset to a variable named airquality_long Using the sleep dataset(use data(sleep) to load it), transform it from long to wide format and assign the resulting wide format dataset to a variable named sleep_wide Use the aggregate() function to group the mtcars dataset by the number of cylinders and calculate the average miles per gallon for each cylinder category. Assign the resulting aggregated dataset to a variable named avg_mpg_by_cyl Use the aggregate() function to calculate the average sepal length for each species (Species). Assign the resulting aggregated dataset to a variable named avg_sepal_length_by_species Create a list named numeric_lists containing numeric vectors, vector 1 contains values from 25 to 32, the second vector contains values from 41 to 48 and the third vector contains values from 7 to 14. Use lapply() to apply an anonymous function that squares each element in each numeric vector. Assign the resulting list to a variable named squared_values Create a list named age_lists containing three numeric vectors: c(17, 21, 3, 19, 50), c(14, 50, 77, 16, 87), c(37, 8, 90, 43, 60). Use sapply() to apply an anonymous function that calculates the mean of each ages vector. For simplification, name the vectors, v1, v2 and v3 respectively. Assign the resulting vector of means to a variable named means Given a matrix mat, that contains numbers from 1 to 9,with NA values at 3 and 8, calculate the mean of non-missing values in each column using apply(). Assign the resulting vector of column-wise means to a variable named column_means Given a list of vectors named scores calculated out of 10 with 3 elements namely v1 which has elements 7, 8 and 9, v2 which contains elements 4, 5 and 6 and v3 which contains 2, 3 to, use lapply() to calculate the cumulative sum for each element in the list. Assign the resulting list of cumulative sums to a variable named other_cumulative_sums "],["general-statistics.html", "Chapter 8 GENERAL STATISTICS 8.1 TABULATING FACTORS AND CREATING CONTINGENCY TABLES 8.2 z-Scores 8.3 TESTING THE MEAN OF A SAMPLE (t-Test) AND ITS CONFIDENCE INTERVAL 8.4 TESTING A SAMPLE PROPORTION AND ITS CONFIDENCE INTERVAL 8.5 8.5 COMPARING THE MEANS OF TWO SAMPLES 8.6 CODE CHALLENGE", " Chapter 8 GENERAL STATISTICS 8.1 TABULATING FACTORS AND CREATING CONTINGENCY TABLES 8.1.1 Tabulating Factors Tabulating factors involves creating frequency tables to summarize the distribution of categorical variables. It provides a quick overview of the count or percentage of observations in each category. R provides various functions for tabulating factors, and two commonly used ones are table() and xtabs() and prop.table() 8.1.2 Tabulation using table() The table() function in R is a simple and versatile way to create contingency tables, which displays the frequency counts of combinations of factor levels. It takes one or more factors as arguments and returns a table of counts. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHNpbXBsZSBjYXRlZ29yaWNhbCB2ZWN0b3JcbmdlbmRlciA8LSBjKFwiRmVtYWxlXCIsIFwiRmVtYWxlXCIsIFwiTWFsZVwiLCBcIkZlbWFsZVwiLCBcIk1hbGVcIiwgXCJGZW1hbGVcIiwgXCJNYWxlXCIsXG4gICAgICAgICAgICBcIk1hbGVcIiwgXCJGZW1hbGVcIiwgXCJGZW1hbGVcIiwgXCJGZW1hbGVcIiwgXCJNYWxlXCIsIFwiRmVtYWxlXCIsIFwiRmVtYWxlXCIsXG4gICAgICAgICAgICBcIk1hbGVcIilcblxuIyBUYWJ1bGF0ZSB0aGUgZ2VuZGVyIHZhcmlhYmxlXG5nZW5kZXJfdGFibGUgPC0gdGFibGUoZ2VuZGVyKVxuXG4jIERpc3BsYXkgdGhlIHRhYmxlXG5nZW5kZXJfdGFibGUifQ== You can also specify two factors like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIG10Y2FycyBkYXRhc2V0XG5kYXRhKG10Y2FycylcblxuIyBGcmVxdWVuY3kgdGFibGUgZm9yIG51bWJlciBvZiBjeWxpbmRlcnMgYW5kIGdlYXIgdHlwZVxudGFibGUobXRjYXJzJGN5bCwgbXRjYXJzJGdlYXIpIn0= 8.1.3 Tabulation using xtabs() The xtabs() function is used to create contingency tables similar to table() but it also allows for the inclusion of a formula argument. This formula approach provides more flexibility in specifying the relationships between factors. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIGRhdGEgZnJhbWUgd2l0aCB0d28gY2F0ZWdvcmljYWwgdmFyaWFibGVzXG5kYXRhIDwtIGRhdGEuZnJhbWUoXG4gIGdlbmRlciA9IGMoXCJNYWxlXCIsIFwiRmVtYWxlXCIsIFwiTWFsZVwiLCBcIk1hbGVcIiwgXCJGZW1hbGVcIiwgXCJGZW1hbGVcIiwgXCJNYWxlXCIsXG4gICAgICAgICAgICAgXCJGZW1hbGVcIiwgXCJNYWxlXCIsIFwiTWFsZVwiLCBcIkZlbWFsZVwiLCBcIkZlbWFsZVwiKSxcbiAgY2F0ZWdvcnkgPSBjKFwiRGVtb2NyYXRcIiwgXCJSZXB1YmxpY2FuXCIsIFwiUmVwdWJsaWNhblwiLCBcIlJlcHVibGljYW5cIixcbiAgICAgICAgICAgICAgIFwiRGVtb2NyYXRcIiwgXCJEZW1vY3JhdFwiLCBcIlJlcHVibGljYW5cIiwgXCJEZW1vY3JhdFwiLCBcIlJlcHVibGljYW5cIixcbiAgICAgICAgICAgICAgIFwiUmVwdWJsaWNhblwiLCBcIkRlbW9jcmF0XCIsIFwiRGVtb2NyYXRcIilcbiAgKVxuXG4jIFRhYnVsYXRlIHRoZSBnZW5kZXIgYW5kIGNhdGVnb3J5IHZhcmlhYmxlc1xuY3Jvc3NfdGFibGUgPC0geHRhYnMofiBnZW5kZXIgKyBjYXRlZ29yeSwgZGF0YSlcblxuIyBEaXNwbGF5IHRoZSBjcm9zcy10YWJ1bGF0aW9uXG5jcm9zc190YWJsZSJ9 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIG10Y2FycyBkYXRhc2V0XG5kYXRhKG10Y2FycylcblxuIyBDb250aW5nZW5jeSB0YWJsZVxueHRhYnMofiBjeWwgKyB2cywgZGF0YSA9IG10Y2FycykifQ== Try in the code chunk below to create a contingency table with the variables cyl and am eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIG10Y2FycyBkYXRhc2V0XG5kYXRhKG10Y2FycylcblxuIyBDb250aW5nZW5jeSB0YWJsZVxueHRhYnMofiBjeWwgKyB2cywgZGF0YSA9IG10Y2FycykifQ== 8.1.4 Tabulation with prop.table() The prop.table() function is used to compute proportions or percentages from contingency tables. It takes a contingency table as its main argument and allows you to specify whether you want proportions across rows, columns, or the entire table. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIG10Y2FycyBkYXRhc2V0XG5kYXRhKG10Y2FycylcblxuXG4jIEV4YW1wbGUgdXNpbmcgcHJvcC50YWJsZSgpXG5wcm9wX3RhYmxlX3JvdyA8LSBwcm9wLnRhYmxlKHRhYmxlX2N5bF92c19nZWFyLCBtYXJnaW4gPSAxKSAgIyBQcm9wb3J0aW9ucyBhY3Jvc3Mgcm93c1xucHJvcF90YWJsZV9jb2wgPC0gcHJvcC50YWJsZSh0YWJsZV9jeWxfdnNfZ2VhciwgbWFyZ2luID0gMikgICMgUHJvcG9ydGlvbnMgYWNyb3NzIGNvbHVtbnNcbnByb3BfdGFibGVfdG90YWwgPC0gcHJvcC50YWJsZSh0YWJsZV9jeWxfdnNfZ2VhcikgICAgIn0= 8.1.5 WHEN TO USE WHICH TABULATION FUNCTION Formula vs. Argument table() takes factors as direct arguments, while xtabs() allows the use of formulas for more complex relationships between factors. Output Format: Both table() and xtabs() produce contingency tables, but the structure of the output can differ slightly. Proportions prop.table() is specifically designed for computing proportions from contingency tables. It allows you to calculate proportions across rows, columns, or the entire table. Flexibility: While table() is straightforward and commonly used for basic tabulation, xtabs() provides more flexibility when dealing with complex relationships between factors. 8.2 z-Scores Z-scores, also known as standard scores, measure how many standard deviations a specific point is away from the mean of a population or sample. They are calculated by subtracting the mean from the individual value and then dividing by the standard deviation. 8.2.1 Applications Identifying outliers: Points with z-scores greater than 3 (or less than -3) are considered outliers and may warrant further investigation. Comparing data points from different distributions: Z-scores allow for standardized comparisons even when data sets have different means and standard deviations. Normalizing data for statistical tests: Many statistical tests assume normality, and z-scores can transform non-normal data into a more normal distribution. 8.2.2 Calculation z = (x - μ) / σ where: - x is the individual value - μ is the population or sample mean - σ is the population or sample standard deviation We can replicate this in R like this: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIENyZWF0ZSBhIHZlY3RvciBvZiB2YWx1ZXNcbnZhbHVlcyA8LSBjKDEwLCAxNSwgMjAsIDI1LCAzMClcblxuIyBDYWxjdWxhdGUgenNjb3JlXG56X3Njb3JlcyA8LSAodmFsdWVzIC0gbWVhbih2YWx1ZXMpKSAvIHNkKHZhbHVlcylcblxuXG4jIFByaW50IHRoZSByZXN1bHRzXG5wcmludCh6X3Njb3JlcykifQ== eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiJoaXN0KHpfc2NvcmVzKSAgIyBIaXN0b2dyYW0gdG8gdmlzdWFsaXplIGRpc3RyaWJ1dGlvblxucXFub3JtKHpfc2NvcmVzKSAgIyBOb3JtYWwgcXVhbnRpbGUtcXVhbnRpbGUgcGxvdCB0byBhc3Nlc3Mgbm9ybWFsaXR5In0= 8.3 TESTING THE MEAN OF A SAMPLE (t-Test) AND ITS CONFIDENCE INTERVAL The t-test is a statistical test used to determine if the mean of a sample is significantly different from a hypothesized population mean. It is used when the population standard deviation is unknown and must be estimated from the sample data. 8.3.1 Types of t-tests: One-sample t-test: Compares the sample mean to a specific hypothesized population mean. Syntax: t.test(x, mu = hypothesized_mean) Paired t-test: Compares the means of two paired groups (e.g., before and after treatment). Syntax: t.test(x, y, paired = TRUE) Independent t-test: Compares the means of two independent groups. Syntax: t.test(x, y) # Assuming equal variances t.test(x, y, var.equal = FALSE) # If variances are not equal 8.3.2 Confidence Interval A confidence interval provides a range of values within which the true population mean is likely to fall with a certain level of confidence (e.g., 95%). It is calculated using the t-statistic and the sample standard deviation. 8.4 TESTING A SAMPLE PROPORTION AND ITS CONFIDENCE INTERVAL The test of a sample proportion determines if the observed proportion of a particular characteristic in a sample is significantly different from a hypothesized population proportion. 8.5 8.5 COMPARING THE MEANS OF TWO SAMPLES Comparing the means of two population samples is a fundamental task in statistical analysis. To do this in R, the fundamental question to ask relevant to the use case is: Are you comparing means from independent samples (different groups) or paired samples (repeated measures) 8.5.1 Choosing the appropriate test 8.5.1.0.1 Independent sample If the sample is an independent sample, you can use a two sample t-test, a Welch’s t-test or a Wilcoxon rank-sum test. In R, you can perform a two sample t-test using the t.test() with the appropriate parameters. The two sample t-test assumes the data is normally distributed. A Welch’s t.test can be employed if equal variances are unrealistic. In R you can use the t.test() function but set the paired argument to true like this paired = TRUE Wilcoxon’s rank-sum test is used as a non-parametric alternative for data that is not normally distributed. The function for this in R is wilcox.test() 8.5.1.0.2 Paired sample For normally distributed differences, you can use the t.test() with paired = TRUE. Another 8.6 CODE CHALLENGE Using table() create a contingency table named penguins_contingency_table using the species and island columns from the penguins dataset. Create a contingency table with xtabs() and assign to the variable penguins_xtabs_table using the species and island columns with a formula from the Palmer Penguins dataset. Calculate the proportions of penguin species for each island using the contingency table created in Challenge 1. Assign the resulting proportions to a variable named penguins_species_proportions Conduct an independent two-sample t-test to compare the miles per gallon, of cars with 4 cylinders (cyl == 4) and cars with 6 cylinders (cyl == 6) in the mtcars dataset. Assign the p-value of the test to a variable named t_test_mpg_vs_cyl_pvalue Using the penguins dataset, calculate the z-scores for the body mass of Chinstrap penguins. Calculate the z-scores relative to the entire dataset and assign the resulting vector to a variable named z_scores_body_mass Calculate the z-scores for the flipper length (flipper_length_mm) of Adelie penguins in the penguins dataset. Calculate the z-scores relative to the entire dataset and assign the resulting vector to a variable named z_scores_flipper_length Use the mtcars dataset. Create a variable named transmission_table that contains the frequency table of the different transmission types (am column) Using the iris dataset, create a variable named iris_species_table that contains the frequency table of the different species of iris flowers Use the penguins dataset. Create a cross-tabulation using xtabs() to display the counts of penguin species (species) based on their island location. Assign the resulting cross-tabulation to a variable named penguin_cross_tab Using the electronics data dataset, tabulate how many electronics fell under which discount category and assign it to discount_types "],["simple-linear-regression-in-r.html", "Chapter 9 SIMPLE LINEAR REGRESSION IN R 9.1 y ~ x 9.2 predict() 9.3 Linear regression take away notes 9.4 CODE CHALLENGE", " Chapter 9 SIMPLE LINEAR REGRESSION IN R 9.1 y ~ x Linear regression is a statistical method for modelling the relationship between two continuous variables: a dependent variable (y) and an independent variable (x). The formula for simple linear regression is y ~ x The output will provide coefficients (intercept and slope) for the linear equation: y = intercept + slope * x. The slope indicates how much y changes for a unit change in x. The intercept indicates the value of y when x is 0.In statistical terms, the dependent variable can also be referred to as the response or the outcome variable whereas the independent variable can also be interchangeably used with the term predictor or explanatory variable. In R, you can perform simple linear regression using the lm() function, which stands for “linear model.” We will illustrate a simple use case of performing simple linear regression in R, but before, we will talk about the set.seed() function in R. This function is often employed to make your code reproducible, ensuring that if you run the same code multiple times, you get the same random numbers. This is particularly useful in situations where randomness is involved, such as in simulations or when splitting data into training and testing sets. In R you can set seed by supplying any number to the set.seed function. Any number you supply to the set.seed() would work as intended. Whenever you’Re performing any operation in R that will involve generation of random numbers or samples, you can use this function before you perform this operation. Do note that the number you supplied must be changed once used to ensure reproducibility, that is, if you set the function to a number, keep this number. Changing it will make your program generate and maintain a new set of random numbers. For the purpose of this course, we will use the argument 1234 for our set.seed() function but do note that the choice of number is personal. You can use absolutely any number you want to. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFNldCBzZWVkIHRvIGVuc3VyZSByZXByb2R1Y2liaWxpdHlcbnNldC5zZWVkKDEyMzQpXG5cbiMgQ3JlYXRlIGEgc2FtcGxlIGRhdGFzZXRcbmRmIDwtIGRhdGEuZnJhbWUoXG4gIHggPSBjKDcsMjAsMTMsNCw1MCwxOCksXG4gIHkgPSBjKDQ0LDEsMjMsOCwyNywxNClcbilcblxuIyBGaXQgdGhlIGxpbmVhciBtb2RlXG5tb2RlbCA8LSBsbSh5IH4geCwgZGF0YSA9IGRmKVxuXG4jIERpc3BsYXkgc3VtbWFyeSBvZiB0aGUgbW9kZWxcbnN1bW1hcnkobW9kZWwpIn0= In the above illustration we showed how to perform basic linear regression in R. We first created a sample dataset with two columns, x and y. We then called the lm() function to fit a linear model to our data. You remember the formular for linear data model: y ~ x where y is the dependent variable and x is the independent variable. After fitting our data with a linear model, we usually want to see the results of the linear model. We can see some information like coefficients, R-squared, residual standard error, F-statistic, intercept, p-values, etc., by calling the function summary() on our linear model. What results are printed when you call the summary function? Let us try another example using a real life dataset, mtcars! We want to model the relationship between the miles per gallon of a car and its weight. In other words, we will like to predict the mpg of a car based on its weight. We will approach that like this eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIGJ1aWx0LWluICdtdGNhcnMnIGRhdGFzZXRcbmRhdGEobXRjYXJzKVxuXG4jIEZpdCBhIGxpbmVhciBtb2RlbFxubW9kZWxfY2FycyA8LSBsbShtcGcgfiB3dCwgZGF0YSA9IG10Y2FycylcblxuIyBEaXNwbGF5IHN1bW1hcnkgb2YgdGhlIG1vZGVsXG5zdW1tYXJ5KG1vZGVsX2NhcnMpIn0= Now in the interactive exercise below, use the iris dataset to model the relationship between petal length and sepal length and print the model summary. As a hint: petal length is our respose variable and sepal length is our predictor variable. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIGlyaXMgZGF0YXNldFxuXG4jIEZpdCBsaW5lYXIgbW9kZWwiLCJzb2x1dGlvbiI6IiMgTG9hZCB0aGUgaXJpcyBkYXRhc2V0XG5pcmlzIDwtIGRhdGFzZXRzOjppcmlzXG5cbiMgRml0IGxpbmVhciBtb2RlbFxubW9kZWxfaXJpcyA8LSBsbShQZXRhbC5MZW5ndGggfiBTZXBhbC5MZW5ndGgsIGRhdGEgPSBpcmlzKVxuXG4jIERpc3BsYXkgbW9kZWwgc3VtbWFyeVxuc3VtbWFyeShtb2RlbF9pcmlzKSJ9 9.1.1 Interpreting summary() results in R When you use the summary() function on a linear regression model (lm object) in R, it provides a summary of various statistics and metrics related to the fitted model. Here are some of the key metrics printed in the summary output for a simple linear regression model: Coefficients Estimate: This is the estimated value of the coefficient for each predictor variable. In simple linear regression, you will have an intercept term ((Intercept)) and a coefficient for the predictor variable (x in lm(y ~ x)). Residuals Residuals: The residuals are the differences between the observed values (y) and the predicted values. They represent the unexplained variability in the data. Statistical Tests t value: The t-value is a measure of how many standard errors the coefficient estimate is away from zero. Larger absolute t-values indicate more evidence against the null hypothesis (that the true coefficient is zero) Pr(&gt;|t|): The p-value associated with the t-test. Small p-values suggest that you can reject the null hypothesis. R-squared The coefficient of determination, R-squared, represents the proportion of variance in the dependent variable (y) that is explained by the independent variable (x). It ranges from 0 to 1, where 1 indicates a perfect fit. Adjusted R-squared This is a modified version of R-squared that takes into account the number of predictors in the model. It penalizes the addition of predictors that do not improve the model significantly. F-statistic This is a measure of how well the entire model explains the variability in the dependent variable. It is associated with an overall p-value (Pr(&gt;F)) that tests whether at least one predictor variable has a significant effect on the dependent variable. AIC and BIC: 1. AIC (Akaike Information Criterion): A measure of the model’s goodness of fit that penalizes models with a higher number of parameters. 2. BIC (Bayesian Information Criterion): Similar to AIC but with a higher penalty for models with more parameters. The metrics you would need to judge your model by will be reliant on your use case. Back to our mtcars model. Based on the summary() notes above, can you see some of the key metrics printed? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgdGhlIGJ1aWx0LWluICdtdGNhcnMnIGRhdGFzZXRcbmRhdGEobXRjYXJzKVxuXG4jIEZpdCBhIGxpbmVhciBtb2RlbFxubW9kZWxfY2FycyA8LSBsbShtcGcgfiB3dCwgZGF0YSA9IG10Y2FycylcblxuIyBEaXNwbGF5IHN1bW1hcnkgb2YgdGhlIG1vZGVsXG5zdW1tYXJ5KG1vZGVsX2NhcnMpIn0= 9.1.2 Visualizing your regression model You can visualize the regression line along with your data using the plot() and abline() functions. Visualising your model allows you to visually assess how well the regression line fits the actual data points. If the line closely follows the data points, it indicates a good fit, whereas deviations might highlight potential issues. You can plot the results of your model like this with base R: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIFBsb3QgdGhlIGRhdGEgcG9pbnRzXG5wbG90KGRmJHgsIGRmJHkpXG5cbiMgQWRkIHRoZSByZWdyZXNzaW9uIGxpbmVcbmFibGluZShtb2RlbCwgY29sID0gXCJyZWRcIikifQ== 9.1.3 Confidence Intervals for regression coefficients In R, you can obtain the confidence intervals for regression coefficients using the confint() function. This can be applied to the linear regression model object obtained from our old friend the lm() function. Here is an example using a simple linear regression model: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEV4YW1wbGUgZGF0YVxuZGYgPC0gZGF0YS5mcmFtZSh4ID0gYygxLCAyLCAzLCA0LCA1KSxcbiAgICAgICAgICAgICAgICAgeSA9IGMoMiwgNCwgNSwgNCwgNSkpXG5cbiMgRml0IHRoZSBsaW5lYXIgbW9kZWxcbm1vZGVsIDwtIGxtKHkgfiB4LCBkYXRhID0gZGYpXG5cbiMgT2J0YWluIGNvbmZpZGVuY2UgaW50ZXJ2YWxzIGZvciByZWdyZXNzaW9uIGNvZWZmaWNpZW50c1xuY29uZl9pbnRlcnZhbHMgPC0gY29uZmludChtb2RlbClcblxuIyBEaXNwbGF5IHRoZSBjb25maWRlbmNlIGludGVydmFsc1xuY29uZl9pbnRlcnZhbHMifQ== The confint() function provides a matrix with two columns: the lower and upper bounds of the confidence intervals for each coefficient. The rows correspond to the intercept and slope in the case of a simple linear regression model. 9.2 predict() The predict() function in R is a handy tool for making predictions using a model you’ve trained. For example, in linear regression, you might have a model that predicts one variable based on another. To use predict(), you just need to provide your fitted model (like one created with lm()) and the new data you want predictions for. In simple terms, if you have a linear regression model that models, let’s say, miles per gallon based on the number of cylinders in a car, you can use predict() to estimate the miles per gallon for new data points (new cars). The function uses the model’s learned patterns to make these predictions. While there are extra options you can explore, for basic predictions, you usually don’t need them. It’s a useful tool for understanding how your model performs and for making informed decisions based on the predictions it provides. Let us see an example of this in motion: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZpdCBhIHNpbXBsZSBsaW5lYXIgcmVncmVzc2lvbiBtb2RlbCB1c2luZyBtdGNhcnMgZGF0YXNldFxubW9kZWwgPC0gbG0obXBnIH4gY3lsLCBkYXRhID0gbXRjYXJzKVxuXG4jIEdlbmVyYXRlIHByZWRpY3Rpb25zIGZvciBtcGcgYmFzZWQgb24gdGhlIG51bWJlciBvZiBjeWxpbmRlcnNcbnByZWRpY3Rpb25zIDwtIHByZWRpY3QobW9kZWwsIG5ld2RhdGEgPSBtdGNhcnMpXG5cbiMgQ29tYmluZSBvcmlnaW5hbCBkYXRhIGFuZCBwcmVkaWN0ZWQgdmFsdWVzIGZvciBjb21wYXJpc29uXG5yZXN1bHQgPC0gY2JpbmQobXRjYXJzLCBQcmVkaWN0ZWRNUEcgPSBwcmVkaWN0aW9ucylcblxuIyBEaXNwbGF5IHRoZSBmaXJzdCBmZXcgcm93cyBvZiB0aGUgY29tYmluZWQgZGF0YVxuaGVhZChyZXN1bHRbLCBjKFwibXBnXCIsIFwiUHJlZGljdGVkTVBHXCIpXSlcblxuIyBWaXN1YWxpemUgdGhlIHJlc3VsdHMgd2l0aCBhIHNjYXR0ZXIgcGxvdCBhbmQgdGhlIHJlZ3Jlc3Npb24gbGluZVxucGxvdChtdGNhcnMkY3lsLCBtdGNhcnMkbXBnLCBtYWluID0gXCJMaW5lYXIgUmVncmVzc2lvbjogbXBnIHZzLiBjeWxcIixcbiAgICAgeGxhYiA9IFwiTnVtYmVyIG9mIEN5bGluZGVyc1wiLCB5bGFiID0gXCJNaWxlcyBQZXIgR2FsbG9uXCIpXG5hYmxpbmUobW9kZWwsIGNvbCA9IFwicmVkXCIpICAjIFBsb3QgdGhlIHJlZ3Jlc3Npb24gbGluZSJ9 eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEZpdCBhIHNpbXBsZSBsaW5lYXIgcmVncmVzc2lvbiBtb2RlbCB1c2luZyBtdGNhcnMgZGF0YXNldFxubW9kZWwgPC0gbG0obXBnIH4gY3lsLCBkYXRhID0gbXRjYXJzKVxuXG4jIEdlbmVyYXRlIHByZWRpY3Rpb25zIGZvciBtcGcgYmFzZWQgb24gdGhlIG51bWJlciBvZiBjeWxpbmRlcnNcbnByZWRpY3Rpb25zIDwtIHByZWRpY3QobW9kZWwsIG5ld2RhdGEgPSBtdGNhcnMpXG5cbiMgQ29tYmluZSBvcmlnaW5hbCBkYXRhIGFuZCBwcmVkaWN0ZWQgdmFsdWVzIGZvciBjb21wYXJpc29uXG5yZXN1bHQgPC0gY2JpbmQobXRjYXJzLCBQcmVkaWN0ZWRNUEcgPSBwcmVkaWN0aW9ucylcblxuIyBEaXNwbGF5IHRoZSBmaXJzdCBmZXcgcm93cyBvZiB0aGUgY29tYmluZWQgZGF0YVxuaGVhZChyZXN1bHRbLCBjKFwibXBnXCIsIFwiUHJlZGljdGVkTVBHXCIpXSlcblxuIyBWaXN1YWxpemUgdGhlIHJlc3VsdHMgd2l0aCBhIHNjYXR0ZXIgcGxvdCBhbmQgdGhlIHJlZ3Jlc3Npb24gbGluZVxucGxvdChtdGNhcnMkY3lsLCBtdGNhcnMkbXBnLCBtYWluID0gXCJMaW5lYXIgUmVncmVzc2lvbjogbXBnIHZzLiBjeWxcIixcbiAgICAgeGxhYiA9IFwiTnVtYmVyIG9mIEN5bGluZGVyc1wiLCB5bGFiID0gXCJNaWxlcyBQZXIgR2FsbG9uXCIpXG5hYmxpbmUobW9kZWwsIGNvbCA9IFwicmVkXCIpICAjIFBsb3QgdGhlIHJlZ3Jlc3Npb24gbGluZSJ9 Based on the work above, can you create a linear regression model that models the relationship between petal length and sepal length from the iris dataset and make predictions with the data and visualize the results in the code chunk below? eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIExvYWQgaXJpcyBkYXRhc2V0XG5kYXRhKGlyaXMpIn0= 9.3 Linear regression take away notes Simple linear regression assumes a linear relationship between y and x. Check for linearity and other assumptions before relying on the model. Use diagnostic plots to assess model fit. For more complex relationships, consider multiple linear regression or other techniques. 9.3.1 Advantages of the simple linear regression model Simplicity and Interpretability: It’s easy to understand and explain, even for those without extensive statistical knowledge. The equation is straightforward, and the coefficients have clear meanings. Ease of Implementation: It’s relatively easy to implement in most statistical software, including R. Flexibility: It can be used for various purposes, including prediction, trend analysis, and hypothesis testing. Robustness: It’s generally robust to minor violations of its assumptions, meaning it can still provide useful results even if the data isn’t perfectly linear. 9.3.2 Limitations of the simple linear regression model Linearity Assumption: A linear regression assumes a linear relationship between the variables. If the relationship is nonlinear, the model may not accurately capture it. Sensitivity to Outliers: Outliers can significantly influence the regression line, potentially leading to misleading results. Overfitting: If the model is too complex for the amount of data, it may overfit, meaning it captures noise in the data rather than the underlying relationship. Limited Predictive Power: It can only predict the value of the dependent variable based on a single independent variable. For more complex relationships involving multiple predictors, multiple linear regression is needed. 9.4 CODE CHALLENGE Perform a linear regression analysis on the mtcars dataset to identify statistically significant variables influencing the prediction of a car’s miles per gallon. These are the following tasks to be undertaken: Assign the resulting linear regression model object to a variable named linear_model. Extract and assign the confidence interval for the regression model to a variable named confidence_interval Generate a summary of the linear regression model, including relevant statistics, and assign it to a variable named model_summary. Finally, use the linear_model to make predictions for the miles per gallon values in the mtcars dataset, and assign the predicted values to a variable named predicted_mpg "],["advanced-topics.html", "Chapter 10 Advanced Topics 10.1 REPRODUCIBILITY AND REPORTS IN R MARKDOWN 10.2 RShiny 10.3 Building Packages in R 10.4 END OF COURSE ASSIGNMENT", " Chapter 10 Advanced Topics 10.1 REPRODUCIBILITY AND REPORTS IN R MARKDOWN 10.1.1 REPRODUCIBILITY Reproducibility refers the ability to accurately replicate the results of a study or analysis using the same data and methods. It’s crucial for scientific integrity, transparency, and collaboration. R Markdown is a powerful tool for creating reproducible reports because it integrates code, text, and output into a single document. 10.1.2 RMarkdown (.Rmd) It’s a file format that allows you to combine Markdown (a simple text formatting language) with R code chunks. You write text, code, and embed results directly in the document. When you “knit” the document, it’s processed to create a formatted output file (HTML, PDF, Word, etc.), combining text, code, and output seamlessly. 10.1.3 RMarkdown’s Key Features for Reproducibility Code Integration: R code chunks are embedded within the document, ensuring all analysis steps are documented and executable. Readers can easily see the code used to generate results, enhancing transparency and understanding. Output Capture: The output of R code chunks, such as tables, figures, and statistical summaries, is automatically inserted into the final document. This eliminates the need for manual copying and pasting, reducing errors and ensuring consistency. Version Control R Markdown files can be easily versioned using tools like Git, preserving the complete history of changes and enabling collaboration. Self-Contained Reports The final output document includes both the code and results, making it a self-contained and reproducible report. Readers can access all necessary information to understand and replicate the analysis. 10.1.4 Using RMarkdown To create an RMarkdown document, ensure that the rmarkdown package is installed. You can install it with install.packages(\"rmarkdown\"). Create a new R Markdown document using RStudio or by using the rmarkdown::draft() function. eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIEEgc2ltcGxlIGxvb2sgb2YgYW4gUk1hcmtkb3duIGRvY3VtZW50XG5cbiMtLS1cbiN0aXRsZTogXCJSZXByb2R1Y2libGUgUmVwb3J0XCJcbiNhdXRob3I6IFwiWW91ciBOYW1lXCJcbiNkYXRlOiBcIkphbnVhcnkgMSwgMjAyM1wiXG4jb3V0cHV0OiBodG1sX2RvY3VtZW50XG4jLS0tXG4jXG4jIEludHJvZHVjdGlvblxuI1xuI1RoaXMgaXMgYW4gZXhhbXBsZSBvZiBhbiBSIE1hcmtkb3duIGRvY3VtZW50LlxuI1xuI2BgYHtyIHNldHVwLCBpbmNsdWRlPUZBTFNFfVxuI2tuaXRyOjpvcHRzX2NodW5rJHNldChlY2hvID0gVFJVRSlcbiNgYGAifQ== 10.2 RShiny Shiny is an R package that allows you to build interactive web applications directly from R. Shiny makes it easy to create interactive dashboards, data visualizations, and web applications without the need for web development skills. With Shiny, you can turn your R code, analyses, and visualizations into interactive and user-friendly web applications. 10.2.1 Key Features of RShiny Reactivity: Shiny is built on the concept of reactivity, where changes in inputs (e.g., sliders, buttons, text inputs) automatically trigger updates in outputs (e.g., plots, tables). This makes it easy to create dynamic and responsive applications. User Interface (UI): Shiny applications have a user interface that can be designed using a combination of R and HTML-like syntax. The UI defines the layout and appearance of the application. Server Logic: The server logic of a Shiny application is where you define the R code that generates outputs based on user inputs. The server function is responsible for handling reactive expressions and rendering outputs. Widgets: Shiny provides a variety of widgets (input elements) that users can interact with, such as sliders, buttons, text inputs, and more. These widgets serve as inputs that trigger changes in the application. Output Elements: Shiny supports a range of output elements, including plots, tables, and HTML elements. These are updated dynamically in response to user interactions. Deployment: Shiny applications can be deployed locally or on web servers. Popular options for deployment include hosting on shinyapps.io, deploying on Shiny Server, or integrating with RStudio Connect. Here’s a simple example of a Shiny application using the mtcars dataset. Run this in your local RStudio app: eyJsYW5ndWFnZSI6InIiLCJzYW1wbGUiOiIjIG10Y2Fyc19zaGlueV9hcHAuUlxuXG4jbGlicmFyeShzaGlueSlcbiNsaWJyYXJ5KGdncGxvdDIpXG4jXG4jIExvYWQgdGhlIG10Y2FycyBkYXRhc2V0XG4jZGF0YShtdGNhcnMpXG4jXG4jIERlZmluZSBVSVxuI3VpIDwtIGZsdWlkUGFnZShcbiMgIHRpdGxlUGFuZWwoXCJTY2F0dGVyIFBsb3Qgb2YgbXRjYXJzIFZhcmlhYmxlc1wiKSxcbiMgIHNpZGViYXJMYXlvdXQoXG4jICAgIHNpZGViYXJQYW5lbChcbiMgICAgICBzZWxlY3RJbnB1dChcInZhcmlhYmxlXCIsIFwiU2VsZWN0IFZhcmlhYmxlOlwiLCBjaG9pY2VzID0gY29sbmFtZXMobXRjYXJzKSxcbiNzZWxlY3RlZCA9IFwiZGlzcFwiKVxuIyAgICApLFxuIyAgICBtYWluUGFuZWwoXG4jICAgICAgcGxvdE91dHB1dChcInNjYXR0ZXJfcGxvdFwiKVxuIyAgICApXG4jICApXG4jKVxuI1xuIyBEZWZpbmUgc2VydmVyIGxvZ2ljXG4jc2VydmVyIDwtIGZ1bmN0aW9uKGlucHV0LCBvdXRwdXQpIHtcbiMgIG91dHB1dCRzY2F0dGVyX3Bsb3QgPC0gcmVuZGVyUGxvdCh7XG4jICAgICMgQ3JlYXRlIGEgc2NhdHRlciBwbG90IGJhc2VkIG9uIHVzZXItc2VsZWN0ZWQgdmFyaWFibGVcbiMgICAgZ2dwbG90KG10Y2FycywgYWVzX3N0cmluZyh4ID0gXCJtcGdcIiwgeSA9IGlucHV0JHZhcmlhYmxlKSkgK1xuIyAgICAgIGdlb21fcG9pbnQoKSArXG4jICAgICAgbGFicyh0aXRsZSA9IHBhc3RlKFwiU2NhdHRlciBQbG90IG9mIG1wZyB2cy5cIiwgaW5wdXQkdmFyaWFibGUpLFxuIyAgICAgICAgICAgeCA9IFwiTWlsZXMgUGVyIEdhbGxvbiAobXBnKVwiLFxuIyAgICAgICAgICAgeSA9IGlucHV0JHZhcmlhYmxlKVxuIyAgfSlcbiN9XG5cbiMgQ3JlYXRlIFNoaW55IGFwcFxuI3NoaW55QXBwKHVpLCBzZXJ2ZXIpIn0= 10.2.2 Some common use cases of RShiny Data exploration and visualization Interactive dashboards Data analysis tools Reproducible research Educational demonstrations Prototypes for web applications 10.2.3 Why Use RShiny Ease of Use: Straightforward syntax and clear structure make it accessible to R users. Interactivity: Fosters engagement and exploration of data through dynamic elements. Flexibility: Accommodates a wide range of applications and visualizations. Reproducibility: Promotes transparency and sharing of analyses. Deployment: Apps can be easily shared online or deployed on servers for wider access. 10.3 Building Packages in R Building packages in R involves creating collections of custom-defined R functions, data, and documentation that can be shared and reused by others. R packages are crucial for sharing code with others, reproducibility, and maintaining a modular and organized structure for your projects. R is the or if not, one of the most popular statistical programming languages and this is in a large part due to its welcome attitude to open-source and its vibrant community. Many programmers have built R packages which have significantly expanded the language’s applicability across diverse domains, including healthcare, statistics, education, and research. 10.3.1 Why Build Packages Organization and Reuse: Consolidate code and data into reusable units for efficient collaboration and sharing. Distribution and Collaboration: Share your work easily with others, fostering collaboration and reproducibility. Documentation and Maintainability: Improve code quality and clarity through documentation and version control. Extensibility: Create custom functions and extensions to tailor R to specific needs. Contribution: Contribute to the R community by sharing your expertise and tools. 10.3.2 Key Steps in Building an R Package Package Structure A typical R package has a specific directory structure. The main components include the R/ directory for R scripts, man/ for manual pages, data/ for data files, inst/ for other files to be installed, and more. The DESCRIPTION file contains metadata about the package, including its name, version, dependencies, and other information. R Scripts Write your R functions and code in the R/ directory. Each function typically resides in a separate .R file. Document your functions using comments and consider adding documentation using the roxygen2 package syntax. Documentation helps users understand how to use your functions. Namespace: Define a namespace file (NAMESPACE) that explicitly exports functions and objects to be accessed by users. This helps avoid conflicts with other packages. Documentation Use the roxygen2 package to generate documentation from comments in your R script files. Documenting your code is essential for helping users understand how to use your functions. Data If your package includes datasets, place them in the data/ directory. Use the data() function in your code to make the data accessible. Vignettes Vignettes are long-form documentation that provide more extensive explanations, use cases, and examples. Place vignettes in the vignettes/ directory. Tests Write test scripts for your functions in the tests/ directory. Testing ensures that your functions behave as expected and helps maintain code reliability. Build the Package Use the devtools package or the built-in R CMD build command to build your package. This process creates a .tar.gz file, which is the compressed source package. Check the Package Run R CMD check or use devtools::check() to perform a comprehensive check on your package. This ensures that your package complies with best practices and does not have any issues. Install and Load Install your package locally using: install.packages(\"path/to/your/package.tar.gz\", repos = NULL, type = \"source\"). Load the package using library(your_package). Version Control If you’re using version control (e.g., Git), commit your package source files and consider sharing your package on platforms like GitHub. Submit to CRAN: If you want to share your package with the broader R community, consider submitting it to the Comprehensive R Archive Network (CRAN). Follow the CRAN submission guidelines. 10.4 END OF COURSE ASSIGNMENT Everything you learned in this course will be put into test for this take home project. You will be using the Wikipedia World Statistics 2023. The final report would be 2 files, a .Rmd file and a knitted PDF file showing your analysis. Workflow: 1. Import the dataset into RStudio and ensure you inspect it to see how it looks like. 2. Check the data types of each of your variables and make small notes of it. 3. For your analysis, summarize your dataset and using plots, add some visualization of different variables. 4. Use lapply to convert some of your data types to the appropriate formats 5. Report on the dataset 6. Use linear regression to answert the question, is HDI correlated with IMF’s GDP forecast? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
